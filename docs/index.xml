<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>arduin.io</title>
    <link>https://arduin.io/</link>
    <description>Recent content on arduin.io</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 29 Feb 2024 17:30:00 +0000</lastBuildDate><atom:link href="https://arduin.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Recommendations for AI news aggregators</title>
      <link>https://arduin.io/blog/rec-ai-news/</link>
      <pubDate>Thu, 29 Feb 2024 17:30:00 +0000</pubDate>
      
      <guid>https://arduin.io/blog/rec-ai-news/</guid>
      <description>The field of artificial intelligence (AI) is moving fast. Keeping up with the vast number of new research papers on your own is daunting: scrolling through twitter all day does not seem like a good use of time. Below is a number of AI news aggregators that I personally use to get curated updates of AI developments on a regular basis without spending all my time looking at papers:
Last week in AI (newsletter/podast) by Andrey Kurenkov, Jacky Liang et al: weekly updates on the latest AI research development.</description>
    </item>
    
    <item>
      <title>The benchmark problems reviving manual evaluation</title>
      <link>https://arduin.io/blog/benchmark-problems/</link>
      <pubDate>Mon, 15 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>https://arduin.io/blog/benchmark-problems/</guid>
      <description>There is a curious trend in machine learning (ML): researchers developing the most capable large language models (LLMs) increasingly evaluate them using manual methods such as red teaming. In red teaming, researchers hire workers to manually try to break the LLM in some form by interacting with it. Similarly, some users (including myself) pick their preferred LLM assistant by manually trying out various models – checking each LLM&amp;rsquo;s &amp;ldquo;vibe&amp;rdquo;. Given that LLM researchers and users both actively seek to automate all sorts of other tasks, red teaming and vibe checks are surprisingly manual evaluation processes.</description>
    </item>
    
    <item>
      <title>Interesting takes on the future of AI in 2023</title>
      <link>https://arduin.io/blog/interesting-ai-viewpoints/</link>
      <pubDate>Wed, 17 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://arduin.io/blog/interesting-ai-viewpoints/</guid>
      <description>In late 2022 and early 2023, we have seen major leaps in the field of AI with generative models like those underpinning the ChatGPT interface. Below are selected commentary pieces by AI researchers, leaders and commentators that make predictions about the future of AI following these leaps. I highly recommend looking at these links – they have been very influential on my own thinking and work.
Geoffrey Hinton: The Godfather of AI on quitting Google to warn of AI risks (podcast) Bill Gates: The age of AI has begun (blog post) Ferenc Huszár: We May be Surprised Again: Why I take LLMs seriously (blog post) Ezra Klein: My view on AI (podcast) Sam Altman: OpenAI CEO on GPT-4, ChatGPT and the Future of AI (podcast) Andrej Karpathy: Emergence of a whole new computing paradigm (twitter post) Hope you find these helpful!</description>
    </item>
    
    <item>
      <title>GPT illustrated: from high-level diagram to vectors and code</title>
      <link>https://arduin.io/blog/gpt-illustrated/</link>
      <pubDate>Fri, 10 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>https://arduin.io/blog/gpt-illustrated/</guid>
      <description>There are many excellent explanations and illustrations of the original transformer (Vaswani&amp;#32; &amp;#32;et&amp;#32;al.,&amp;#32;2017 Vaswani,&amp;#32; A.,&amp;#32; Shazeer,&amp;#32; N.,&amp;#32; Parmar,&amp;#32; N.,&amp;#32; Uszkoreit,&amp;#32; J.,&amp;#32; Jones,&amp;#32; L.,&amp;#32; Gomez,&amp;#32; A.,&amp;#32; Kaiser,&amp;#32; \.&amp;#32;&amp;amp;&amp;#32;Polosukhin,&amp;#32; I. &amp;#32; (2017). &amp;#32;Attention is all you need. Advances in neural information processing systems,&amp;#32;30. ) and generative pre-trained transformer (GPT) (Radford&amp;#32; &amp;#32;et&amp;#32;al.,&amp;#32;2018 Radford,&amp;#32; A.,&amp;#32; Narasimhan,&amp;#32; K.,&amp;#32; Salimans,&amp;#32; T.&amp;#32;&amp;amp;&amp;#32;Sutskever,&amp;#32; I. &amp;#32; (2018). &amp;#32;Improving language understanding by generative pre-training.&amp;#32;Retrieved from&amp;#32; https://www.mikecaptain.com/resources/pdf/GPT-1.pdf ) architectures. For example, I can highly recommend the write-up by Turner&amp;#32;(2023 Turner,&amp;#32; R.</description>
    </item>
    
    <item>
      <title>A short exploration of language model evaluation approaches</title>
      <link>https://arduin.io/blog/eval-exploration/</link>
      <pubDate>Mon, 06 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>https://arduin.io/blog/eval-exploration/</guid>
      <description>Disclaimer: This post collects some notes from exploring language model evaluation approaches in early 2023. It will (likely) be outdated by the time you read this. Improvement suggestions are welcome and can be sent to contact (at) arduin.io.
1. Introduction Language models (LMs) are notoriosly difficult to evaluate. Modern LMs are used for a wide variety of complex downstream tasks, such as text translation or conversation. This diversity of tasks means that no single metric can capture overall language model performance.</description>
    </item>
    
    
    
    
    
    
  </channel>
</rss>
