<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>A short exploration of language model evaluation approaches | arduin.io</title>
<meta name="keywords" content="">
<meta name="description" content="Disclaimer: This post collects some notes from exploring language model evaluation approaches in early 2023. It will (likely) be outdated by the time you read this. Improvement suggestions are welcome and can be sent to contact (at) arduin.io.
1. Introduction Language models (LMs) are notoriosly difficult to evaluate. Modern LMs are used for a wide variety of complex downstream tasks, such as text translation or conversation. This diversity of tasks means that no single metric can capture overall language model performance.">
<meta name="author" content="Arduin Findeis">
<link rel="canonical" href="https://arduin.io/blog/eval-exploration/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.5bc4f8cb762aefc18ccd0fa3270fe39efaeea9d556d18c4c77b417cb328985be.css" integrity="sha256-W8T4y3Yq78GMzQ&#43;jJw/jnvruqdVW0YxMd7QXyzKJhb4=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://arduin.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://arduin.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://arduin.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://arduin.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://arduin.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://arduin.io/blog/eval-exploration/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><script data-goatcounter="https://gbqtk.goatcounter.com/count"
        async src="//gc.zgo.at/count.js"></script><meta property="og:title" content="A short exploration of language model evaluation approaches" />
<meta property="og:description" content="Disclaimer: This post collects some notes from exploring language model evaluation approaches in early 2023. It will (likely) be outdated by the time you read this. Improvement suggestions are welcome and can be sent to contact (at) arduin.io.
1. Introduction Language models (LMs) are notoriosly difficult to evaluate. Modern LMs are used for a wide variety of complex downstream tasks, such as text translation or conversation. This diversity of tasks means that no single metric can capture overall language model performance." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://arduin.io/blog/eval-exploration/" /><meta property="article:section" content="blog" />
<meta property="article:published_time" content="2023-03-06T00:00:00+00:00" />
<meta property="article:modified_time" content="2023-03-06T00:00:00+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="A short exploration of language model evaluation approaches"/>
<meta name="twitter:description" content="Disclaimer: This post collects some notes from exploring language model evaluation approaches in early 2023. It will (likely) be outdated by the time you read this. Improvement suggestions are welcome and can be sent to contact (at) arduin.io.
1. Introduction Language models (LMs) are notoriosly difficult to evaluate. Modern LMs are used for a wide variety of complex downstream tasks, such as text translation or conversation. This diversity of tasks means that no single metric can capture overall language model performance."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Blog",
      "item": "https://arduin.io/blog/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "A short exploration of language model evaluation approaches",
      "item": "https://arduin.io/blog/eval-exploration/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "A short exploration of language model evaluation approaches",
  "name": "A short exploration of language model evaluation approaches",
  "description": "Disclaimer: This post collects some notes from exploring language model evaluation approaches in early 2023. It will (likely) be outdated by the time you read this. Improvement suggestions are welcome and can be sent to contact (at) arduin.io.\n1. Introduction Language models (LMs) are notoriosly difficult to evaluate. Modern LMs are used for a wide variety of complex downstream tasks, such as text translation or conversation. This diversity of tasks means that no single metric can capture overall language model performance.",
  "keywords": [
    
  ],
  "articleBody": " Disclaimer: This post collects some notes from exploring language model evaluation approaches in early 2023. It will (likely) be outdated by the time you read this. Improvement suggestions are welcome and can be sent to contact (at) arduin.io.\n1. Introduction Language models (LMs) are notoriosly difficult to evaluate. Modern LMs are used for a wide variety of complex downstream tasks, such as text translation or conversation. This diversity of tasks means that no single metric can capture overall language model performance. Even for individual tasks, it can be difficult to come up with well-setup benchmarks to measure performance. Some benchmarks have been shown to allow models to achieve top performance without truly mastering the underlying tasks (Niven \u0026 Kao, 2019 Niven, T. \u0026 Kao, H. (2019). Probing Neural Network Comprehension of Natural Language Arguments. Association for Computational Linguistics. https://doi.org/10.18653/v1/P19-1459 ; Zellers et al., 2019 Zellers, R., Holtzman, A., Bisk, Y., Farhadi, A. \u0026 Choi, Y. (2019). HellaSwag: Can a Machine Really Finish Your Sentence?. https://doi.org/10.48550/arXiv.1905.07830 ). Unintended statistical biases in the training data can allow superficial learning using (basically) just word counts – without solving the intended (more complex) linguistic task. Yet, as LMs become ever more capable and see real-world deployment, reliable and interpretable evaluation methods only become more important.\nIn this post I first go through a few examples of current standard benchmarks in natural language processing (NLP) to illustrate the status quo of LM evaluation. In the second part, I consider some novel approaches that have recently been proposed to better capture modern models’ capabilities.\n2. Standard benchmarks There is a vast collection of NLP benchmarks. To narrow down the scope of this post, I focus on benchmarks used to evaluate InstructGPT (Ouyang et al., 2022 Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., Schulman, J., Hilton, J., Kelton, F., Miller, L., Simens, M., Askell, A., Welinder, P., Christiano, P., Leike, J. \u0026 Lowe, R. (2022). Training language models to follow instructions with human feedback. Retrieved from http://arxiv.org/abs/2203.02155 ) (closely related to OpenAI’s ChatGPT models) as illustrative examples. The aim behind InstructGPT (and related large language models) is to provide a multi-purpose model that can be used for a diverse set of downstream tasks. This diversity is also reflected in the kind of benchmarks these models are tested on. In this post, I only consider examples of scalable evaluation methods that do not require direct human feedback.\nStandard benchmarks can be split into two categories: task-specific and alignment benchmarks. Task-specific benchmarks attempt to evaluate the models ability to perform specific tasks, such as translation or discrete reasoning. Each benchmark typically covers one such task. Alignment benchmarks cover additional text charateristics we would like our LM output to have, such as not being racist or being unbiased. These additional characteristics can be more difficult to rigorously define and test for. Nevertheless, these characteristics are very important for deploying LMs safely. The figure below provides an overview of standard NLP benchmarks. Overview of NLP benchmarks.\nTask-specific benchmarks Below is a list of some of the task-specific benchmarks used for InstructGPT.\nSQuAD\n(Rajpurkar et al., 2018 Rajpurkar, P., Jia, R. \u0026 Liang, P. (2018). Know What You Don’t Know: Unanswerable Questions for SQuAD. https://doi.org/10.48550/arXiv.1806.03822 ) The Stanford Question Answering Dataset (SQuAD) v2.0 consists of a large corpus of small text excerpts from Wikipedia articles (100,000+). Each text has corresponding questions and anwers created by crowdworkers. The original SQuAD v1.0 (Rajpurkar et al., 2016 Rajpurkar, P., Zhang, J., Lopyrev, K. \u0026 Liang, P. (2016). SQuAD: 100,000+ Questions for Machine Comprehension of Text. https://doi.org/10.48550/arXiv.1606.05250 ) was improved in v2.0 to include unanswerable questions. See example questions from both papers below. Answerable questions (v1.0). Figure from Rajpurkar et al. (2016 Rajpurkar, P., Zhang, J., Lopyrev, K. \u0026 Liang, P. (2016). SQuAD: 100,000+ Questions for Machine Comprehension of Text. https://doi.org/10.48550/arXiv.1606.05250 ). Unanswerable questions (v2.0). Figure from Rajpurkar et al. (2018 Rajpurkar, P., Jia, R. \u0026 Liang, P. (2018). Know What You Don’t Know: Unanswerable Questions for SQuAD. https://doi.org/10.48550/arXiv.1806.03822 ). DROP\n(Dua et al., 2019 Dua, D., Wang, Y., Dasigi, P., Stanovsky, G., Singh, S. \u0026 Gardner, M. (2019). DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs. https://doi.org/10.48550/arXiv.1903.00161 ) The DROP dataset aims to assess models’ ability in discrete reasoning over text in a paragraph (DROP). The dataset consists of 96,000 questions. Given a passage of text, the model is given a question that requires reasoning using discrete operations such as addition, counting, or sorting. See example questions below. Top four reasoning operation example. Figure from Dua et al. (2019 Dua, D., Wang, Y., Dasigi, P., Stanovsky, G., Singh, S. \u0026 Gardner, M. (2019). DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs. https://doi.org/10.48550/arXiv.1903.00161 ).\nHellaSwag\n(Zellers et al., 2019 Zellers, R., Holtzman, A., Bisk, Y., Farhadi, A. \u0026 Choi, Y. (2019). HellaSwag: Can a Machine Really Finish Your Sentence?. https://doi.org/10.48550/arXiv.1905.07830 ) The HellaSwag dataset consists of 70,000 questions attempting to evaluate the commonsense natural language inference ability of a model. Given a text fragment referred to as context, the model is asked to select the most plausible of multiple possible endings. HellaSwag is an extension of the SWAG data set by Zellers et al. (2018 Zellers, R., Bisk, Y., Schwartz, R. \u0026 Choi, Y. (2018). SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference. https://doi.org/10.48550/arXiv.1808.05326 ). In addition to the text data from video captioning used in SWAG, HellaSwag adds text data from WikiHow. Both datasets use adverserial filtering to address the issue of annotation artifacts, where human labellers leave unintended biases in wrong labels. During the data generation a generator and a discriminator model are jointly used to filter out endings that are too easy to distinguish. With this iterative process, this data set provides a template how to come up with more challenging data sets for ever more capable language models. Example question answered by a BERT model, once correct (blue) and once incorrect (red). The bold text indicates the correct answer. Figure from Zellers et al. (2019 Zellers, R., Holtzman, A., Bisk, Y., Farhadi, A. \u0026 Choi, Y. (2019). HellaSwag: Can a Machine Really Finish Your Sentence?. https://doi.org/10.48550/arXiv.1905.07830 ).\nWMT 2015 French to English translation\n(Bojar et al., 2015 Bojar, O., Chatterjee, R., Federmann, C., Haddow, B., Huck, M., Hokamp, C., Koehn, P., Logacheva, V., Monz, C., Negri, M., Post, M., Scarton, C., Specia, L. \u0026 Turchi, M. (2015). Findings of the 2015 Workshop on Statistical Machine Translation. Proceedings of the Tenth Workshop on Statistical Machine Translation. 1–46. Retrieved from https://www.research.ed.ac.uk/en/publications/findings-of-the-2015-workshop-on-statistical-machine-translation ) A dataset challenges a model to translate from french text to english text. In the original workshop, models were evaluated using human annotators that make a pairwise comparison of the translation of the same text by different systems. For purpose of evaluating InstructGPT instead of the human evaluation the automatic translation quality score BLEU (Papineni et al., 2002 Papineni, K., Roukos, S., Ward, T. \u0026 Zhu, W. (2002). BLEU: a method for automatic evaluation of machine translation. ) was used. Screenshot of human evaluation interface with example translation task from Russian to English. Figure from Bojar et al. (2015 Bojar, O., Chatterjee, R., Federmann, C., Haddow, B., Huck, M., Hokamp, C., Koehn, P., Logacheva, V., Monz, C., Negri, M., Post, M., Scarton, C., Specia, L. \u0026 Turchi, M. (2015). Findings of the 2015 Workshop on Statistical Machine Translation. Proceedings of the Tenth Workshop on Statistical Machine Translation. 1–46. Retrieved from https://www.research.ed.ac.uk/en/publications/findings-of-the-2015-workshop-on-statistical-machine-translation ).\nAlignment benchmarks In addition to solving a primary task like creating good autocomplete suggestions, we likely also want to make sure that the generated text is not racist or insulting. A number of dedicated benchmarks were created to address these secondary human alignment considerations.\nRealToxicityPrompts\n(Gehman et al., 2020 Gehman, S., Gururangan, S., Sap, M., Choi, Y. \u0026 Smith, N. (2020). RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models. https://doi.org/10.48550/arXiv.2009.11462 ) RealToxicityPrompts consists of 100,000 partial sentences that, when comleted by an LM, may result in racist, sexist or otherwise toxic language. The prompts are given to the LM in a conditional language generation (or auto complete) task. The Perspective API is used to evaluate the toxicity. The use of this external API as a black-box evaluation method means that the results may not be reproducible - as the API’s output may change or be discontinued. More generally, as the authors point out, current methods are unable to adapt an LM to never say toxic things. This limitations presents serious challenges for the safe deployment of LM-based applications. Prompts from the RealToxicityPrompts data set. Figure from Gehman et al. (2020 Gehman, S., Gururangan, S., Sap, M., Choi, Y. \u0026 Smith, N. (2020). RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models. https://doi.org/10.48550/arXiv.2009.11462 ).\nWinogender\n(Rudinger et al., 2018 Rudinger, R., Naradowsky, J., Leonard, B. \u0026 Van Durme, B. (2018). Gender Bias in Coreference Resolution. https://doi.org/10.48550/arXiv.1804.09301 ) The Winogender data set aims to detect gender bias in language models. The data set consists of a number of similar sentences that reference occupations and their gender. For the evaluation of InstructGPT (as far as I understand it), pairs of the sentences that only vary in gender were considered. Then the relative probability of produce one of the sentences was computed, to see for example if the model thought paramedics are more likely to be male.\nWinogender example. Figure from Rudinger et al. (2018 Rudinger, R., Naradowsky, J., Leonard, B. \u0026 Van Durme, B. (2018). Gender Bias in Coreference Resolution. https://doi.org/10.48550/arXiv.1804.09301 ).\nCrowS-Pairs\n(Nangia et al., 2020 Nangia, N., Vania, C., Bhalerao, R. \u0026 Bowman, S. (2020). CrowS-Pairs: A Challenge Dataset for Measuring Social Biases in Masked Language Models. https://doi.org/10.48550/arXiv.2010.00133 ) The CrowS-Pairs dataset consists of 1508 pairs of sentences, each with one more stereotyping than the other. The pairs cover various bias including race, religion and age. In the context of InstructGPT, the dataset is used similarly to Winogender: the probability of computing the more stereotyping sentence is computed. CrowS-Pairs. Figure from Nangia et al. (2020 Nangia, N., Vania, C., Bhalerao, R. \u0026 Bowman, S. (2020). CrowS-Pairs: A Challenge Dataset for Measuring Social Biases in Masked Language Models. https://doi.org/10.48550/arXiv.2010.00133 ).\nTruthfulQA\n(Lin et al., 2022 Lin, S., Hilton, J. \u0026 Evans, O. (2022). TruthfulQA: Measuring How Models Mimic Human Falsehoods. https://doi.org/10.48550/arXiv.2109.07958 ) The TruthfulQA benchmark consists of 817 questions, each crafted such that some humans might answer them incorrectly due to misconceptions. The authors used both human and automated evaluation to assess the truthfullness of model answers. They demonstrated that a finetuned GPT-3 model was 90-96% accurate in detecting truthfulness of answers by other models. TruthfulQA examples. Figure from Lin et al. (2022 Lin, S., Hilton, J. \u0026 Evans, O. (2022). TruthfulQA: Measuring How Models Mimic Human Falsehoods. https://doi.org/10.48550/arXiv.2109.07958 ).\nIn addition to the benchmarks described above, InstructGPT was also evaluated on the following benchmarks: SST (Socher et al., 2013 Socher, R., Perelygin, A., Wu, J., Chuang, J., Manning, C., Ng, A. \u0026 Potts, C. (2013). Recursive deep models for semantic compositionality over a sentiment treebank. ), RTE and WSC parts of SuperGLUE (Wang et al., 2019 Wang, A., Pruksachatkun, Y., Nangia, N., Singh, A., Michael, J., Hill, F., Levy, O. \u0026 Bowman, S. (2019). SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems. Curran Associates, Inc.. Retrieved from https://proceedings.neurips.cc/paper/2019/hash/4496bf24afe7fab6f046bf4923da8de6-Abstract.html ), CNN/Daily Mail Summarization (Nallapati et al., 2016 Nallapati, R., Zhou, B., santos, C., Gulcehre, C. \u0026 Xiang, B. (2016). Abstractive Text Summarization Using Sequence-to-Sequence RNNs and Beyond. https://doi.org/10.48550/arXiv.1602.06023 ), and Reddit TLDR Summarization (Völske et al., 2017 Völske, M., Potthast, M., Syed, S. \u0026 Stein, B. (2017). Tl; dr: Mining reddit to learn automatic summarization. ). Further, there is a large number of additional benchmarks that were not considered for InstructGPT. For examples see the list of 200+ benchmarks available in the lm-evaluation-harness by EleutherAI.\n3. Novel Benchmarks LM-generated benchmarks Perez et al. (2022 Perez, E., , Lukošiūtė, K., Nguyen, K., Chen, E., Heiner, S., Pettit, C., Olsson, C., Kundu, S., Kadavath, S., Jones, A., Chen, A., Mann, B., Israel, B., Seethor, B., McKinnon, C., Olah, C., Yan, D., Amodei, D., Amodei, D., Drain, D., Li, D., Tran-Johnson, E., Khundadze, G., Kernion, J., Landis, J., Kerr, J., Mueller, J., Hyun, J., Landau, J., Ndousse, K., Goldberg, L., Lovitt, L., Lucas, M., Sellitto, M., Zhang, M., Kingsland, N., Elhage, N., Joseph, N., Mercado, N., DasSarma, N., Rausch, O., Larson, R., McCandlish, S., Johnston, S., Kravec, S., Showk, S., Lanham, T., Telleen-Lawton, T., Brown, T., Henighan, T., Hume, T., Bai, Y., Hatfield-Dodds, Z., Clark, J., Bowman, S., Askell, A., Grosse, R., Hernandez, D., Ganguli, D., Hubinger, E., Schiefer, N. \u0026 Kaplan, J. (2022). Discovering Language Model Behaviors with Model-Written Evaluations. https://doi.org/10.48550/arXiv.2212.09251 ) introduce evaluation data sets generated with the help of LMs. They create a variety of data sets, from simple “yes/no” and multiple choice questions to bias detecting schema similar to Winogender (Rudinger et al., 2018 Rudinger, R., Naradowsky, J., Leonard, B. \u0026 Van Durme, B. (2018). Gender Bias in Coreference Resolution. https://doi.org/10.48550/arXiv.1804.09301 ). Compared to the conventional approach, they demonstrate a highly efficient data set generation process. Their approach may influence the generation of many future data sets.\nRed teaming Ganguli et al. (2022 Ganguli, D., Lovitt, L., Kernion, J., Askell, A., Bai, Y., Kadavath, S., Mann, B., Perez, E., Schiefer, N., Ndousse, K., Jones, A., Bowman, S., Chen, A., Conerly, T., DasSarma, N., Drain, D., Elhage, N., El-Showk, S., Fort, S., Hatfield-Dodds, Z., Henighan, T., Hernandez, D., Hume, T., Jacobson, J., Johnston, S., Kravec, S., Olsson, C., Ringer, S., Tran-Johnson, E., Amodei, D., Brown, T., Joseph, N., McCandlish, S., Olah, C., Kaplan, J. \u0026 Clark, J. (2022). Red Teaming Language Models to Reduce Harms: Methods, Scaling Behaviors, and Lessons Learned. https://doi.org/10.48550/arXiv.2209.07858 ) share their experience manually red-teaming LMs. They define LM read teaming as “using manual or automated methods to adversarially probe a language model for harmful outputs, and then updating the model to avoid such outputs”. Perez et al. (2022 Perez, E., Huang, S., Song, F., Cai, T., Ring, R., Aslanides, J., Glaese, A., McAleese, N. \u0026 Irving, G. (2022). Red Teaming Language Models with Language Models. https://doi.org/10.48550/arXiv.2202.03286 ) introduce an automated version of red teaming, where the red team itself is a language model.\n4. Conclusion In this post, I gave an overview of some of the NLP benchmarks used for evaluating modern language models (LMs), such as InstructGPT. Despite best efforts and in many ways impressive performance, the output of current state-of-the-art LMs often fails to satisfy many desirable characterics, such as truthfulness. Reliably quantifying these issues presents on important step towards building better LMs and developing downstream applications. Adaptive benchmarks, such as HellaSwag with adverserial filtering (Zellers et al., 2019 Zellers, R., Holtzman, A., Bisk, Y., Farhadi, A. \u0026 Choi, Y. (2019). HellaSwag: Can a Machine Really Finish Your Sentence?. https://doi.org/10.48550/arXiv.1905.07830 ), present one promising direction to creating benchmarks that co-evolve as models grow more and more powerful.\nAcknowledgements I would like to thank Simon Mathis for pointing me to the excellent paper by Niven \u0026 Kao (2019 Niven, T. \u0026 Kao, H. (2019). Probing Neural Network Comprehension of Natural Language Arguments. Association for Computational Linguistics. https://doi.org/10.18653/v1/P19-1459 ).\nReferences Bojar, O., Chatterjee, R., Federmann, C., Haddow, B., Huck, M., Hokamp, C., Koehn, P., Logacheva, V., Monz, C., Negri, M., Post, M., Scarton, C., Specia, L. \u0026 Turchi, M. (2015). Findings of the 2015 Workshop on Statistical Machine Translation. Proceedings of the Tenth Workshop on Statistical Machine Translation. 1–46. Retrieved from https://www.research.ed.ac.uk/en/publications/findings-of-the-2015-workshop-on-statistical-machine-translation Dua, D., Wang, Y., Dasigi, P., Stanovsky, G., Singh, S. \u0026 Gardner, M. (2019). DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs. https://doi.org/10.48550/arXiv.1903.00161 Ganguli, D., Lovitt, L., Kernion, J., Askell, A., Bai, Y., Kadavath, S., Mann, B., Perez, E., Schiefer, N., Ndousse, K., Jones, A., Bowman, S., Chen, A., Conerly, T., DasSarma, N., Drain, D., Elhage, N., El-Showk, S., Fort, S., Hatfield-Dodds, Z., Henighan, T., Hernandez, D., Hume, T., Jacobson, J., Johnston, S., Kravec, S., Olsson, C., Ringer, S., Tran-Johnson, E., Amodei, D., Brown, T., Joseph, N., McCandlish, S., Olah, C., Kaplan, J. \u0026 Clark, J. (2022). Red Teaming Language Models to Reduce Harms: Methods, Scaling Behaviors, and Lessons Learned. https://doi.org/10.48550/arXiv.2209.07858 Gehman, S., Gururangan, S., Sap, M., Choi, Y. \u0026 Smith, N. (2020). RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models. https://doi.org/10.48550/arXiv.2009.11462 Lin, S., Hilton, J. \u0026 Evans, O. (2022). TruthfulQA: Measuring How Models Mimic Human Falsehoods. https://doi.org/10.48550/arXiv.2109.07958 Nallapati, R., Zhou, B., santos, C., Gulcehre, C. \u0026 Xiang, B. (2016). Abstractive Text Summarization Using Sequence-to-Sequence RNNs and Beyond. https://doi.org/10.48550/arXiv.1602.06023 Nangia, N., Vania, C., Bhalerao, R. \u0026 Bowman, S. (2020). CrowS-Pairs: A Challenge Dataset for Measuring Social Biases in Masked Language Models. https://doi.org/10.48550/arXiv.2010.00133 Niven, T. \u0026 Kao, H. (2019). Probing Neural Network Comprehension of Natural Language Arguments. Association for Computational Linguistics. https://doi.org/10.18653/v1/P19-1459 Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., Schulman, J., Hilton, J., Kelton, F., Miller, L., Simens, M., Askell, A., Welinder, P., Christiano, P., Leike, J. \u0026 Lowe, R. (2022). Training language models to follow instructions with human feedback. Retrieved from http://arxiv.org/abs/2203.02155 Papineni, K., Roukos, S., Ward, T. \u0026 Zhu, W. (2002). BLEU: a method for automatic evaluation of machine translation. Perez, E., , Lukošiūtė, K., Nguyen, K., Chen, E., Heiner, S., Pettit, C., Olsson, C., Kundu, S., Kadavath, S., Jones, A., Chen, A., Mann, B., Israel, B., Seethor, B., McKinnon, C., Olah, C., Yan, D., Amodei, D., Amodei, D., Drain, D., Li, D., Tran-Johnson, E., Khundadze, G., Kernion, J., Landis, J., Kerr, J., Mueller, J., Hyun, J., Landau, J., Ndousse, K., Goldberg, L., Lovitt, L., Lucas, M., Sellitto, M., Zhang, M., Kingsland, N., Elhage, N., Joseph, N., Mercado, N., DasSarma, N., Rausch, O., Larson, R., McCandlish, S., Johnston, S., Kravec, S., Showk, S., Lanham, T., Telleen-Lawton, T., Brown, T., Henighan, T., Hume, T., Bai, Y., Hatfield-Dodds, Z., Clark, J., Bowman, S., Askell, A., Grosse, R., Hernandez, D., Ganguli, D., Hubinger, E., Schiefer, N. \u0026 Kaplan, J. (2022). Discovering Language Model Behaviors with Model-Written Evaluations. https://doi.org/10.48550/arXiv.2212.09251 Perez, E., Huang, S., Song, F., Cai, T., Ring, R., Aslanides, J., Glaese, A., McAleese, N. \u0026 Irving, G. (2022). Red Teaming Language Models with Language Models. https://doi.org/10.48550/arXiv.2202.03286 Rajpurkar, P., Zhang, J., Lopyrev, K. \u0026 Liang, P. (2016). SQuAD: 100,000+ Questions for Machine Comprehension of Text. https://doi.org/10.48550/arXiv.1606.05250 Rajpurkar, P., Jia, R. \u0026 Liang, P. (2018). Know What You Don’t Know: Unanswerable Questions for SQuAD. https://doi.org/10.48550/arXiv.1806.03822 Rudinger, R., Naradowsky, J., Leonard, B. \u0026 Van Durme, B. (2018). Gender Bias in Coreference Resolution. https://doi.org/10.48550/arXiv.1804.09301 Socher, R., Perelygin, A., Wu, J., Chuang, J., Manning, C., Ng, A. \u0026 Potts, C. (2013). Recursive deep models for semantic compositionality over a sentiment treebank. Völske, M., Potthast, M., Syed, S. \u0026 Stein, B. (2017). Tl; dr: Mining reddit to learn automatic summarization. Wang, A., Pruksachatkun, Y., Nangia, N., Singh, A., Michael, J., Hill, F., Levy, O. \u0026 Bowman, S. (2019). SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems. Curran Associates, Inc.. Retrieved from https://proceedings.neurips.cc/paper/2019/hash/4496bf24afe7fab6f046bf4923da8de6-Abstract.html Zellers, R., Bisk, Y., Schwartz, R. \u0026 Choi, Y. (2018). SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference. https://doi.org/10.48550/arXiv.1808.05326 Zellers, R., Holtzman, A., Bisk, Y., Farhadi, A. \u0026 Choi, Y. (2019). HellaSwag: Can a Machine Really Finish Your Sentence?. https://doi.org/10.48550/arXiv.1905.07830 Appendix A. InstructGPT automatic evaluation results Whilst the ChatGPT results on these benchmarks are unkown, we can look at the results of InstructGPT to get glimpse of the likely capabilities of ChatGPT. The figure below is taken from the InstructGPT paper (Ouyang et al., 2022 Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., Schulman, J., Hilton, J., Kelton, F., Miller, L., Simens, M., Askell, A., Welinder, P., Christiano, P., Leike, J. \u0026 Lowe, R. (2022). Training language models to follow instructions with human feedback. Retrieved from http://arxiv.org/abs/2203.02155 ).\nResults of InstructGPT on public NLP benchmarks. Figure from Ouyang et al. (2022 Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., Schulman, J., Hilton, J., Kelton, F., Miller, L., Simens, M., Askell, A., Welinder, P., Christiano, P., Leike, J. \u0026 Lowe, R. (2022). Training language models to follow instructions with human feedback. Retrieved from http://arxiv.org/abs/2203.02155 ).\nVersion history v0.3 (2023-11-23): minor corrections and tweaks. v0.2 (2023-03-14): major rewrite, including adding section on novel evaluation methods. v0.1 (2023-03-06): first public draft. ",
  "wordCount" : "3271",
  "inLanguage": "en",
  "datePublished": "2023-03-06T00:00:00Z",
  "dateModified": "2023-03-06T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Arduin Findeis"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://arduin.io/blog/eval-exploration/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "arduin.io",
    "logo": {
      "@type": "ImageObject",
      "url": "https://arduin.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://arduin.io/" accesskey="h" title="arduin.io (Alt + H)">arduin.io</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://arduin.io/" title="Home">
                    <span>Home</span>
                </a>
            </li>
            <li>
                <a href="https://arduin.io/research" title="Research">
                    <span>Research</span>
                </a>
            </li>
            <li>
                <a href="https://arduin.io/projects" title="Projects">
                    <span>Projects</span>
                </a>
            </li>
            <li>
                <a href="https://arduin.io/bio" title="Bio">
                    <span>Bio</span>
                </a>
            </li>
            <li>
                <a href="https://arduin.io/blog" title="Blog">
                    <span>Blog</span>
                </a>
            </li>
            <li>
                <a href="https://arduin.io/newsletter" title="Newsletter">
                    <span>Newsletter</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <link rel="stylesheet" type="text/css" href="/hugo-cite.css" />
    
    <h1 class="post-title entry-hint-parent">
      A short exploration of language model evaluation approaches
    </h1>
    
    <div class="post-meta"><span title='2023-03-06 00:00:00 +0000 UTC'>March 6, 2023</span>&nbsp;·&nbsp;16 min&nbsp;·&nbsp;Arduin Findeis

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#1-introduction" aria-label="1. Introduction">1. Introduction</a></li>
                <li>
                    <a href="#2-standard-benchmarks" aria-label="2. Standard benchmarks">2. Standard benchmarks</a><ul>
                        
                <li>
                    <a href="#task-specific-benchmarks" aria-label="Task-specific benchmarks">Task-specific benchmarks</a></li>
                <li>
                    <a href="#alignment-benchmarks" aria-label="Alignment benchmarks">Alignment benchmarks</a></li></ul>
                </li>
                <li>
                    <a href="#3-novel-benchmarks" aria-label="3. Novel Benchmarks">3. Novel Benchmarks</a><ul>
                        
                <li>
                    <a href="#lm-generated-benchmarks" aria-label="LM-generated benchmarks">LM-generated benchmarks</a></li>
                <li>
                    <a href="#red-teaming" aria-label="Red teaming">Red teaming</a></li></ul>
                </li>
                <li>
                    <a href="#4-conclusion" aria-label="4. Conclusion">4. Conclusion</a></li>
                <li>
                    <a href="#acknowledgements" aria-label="Acknowledgements">Acknowledgements</a></li>
                <li>
                    <a href="#references" aria-label="References">References</a></li>
                <li>
                    <a href="#appendix" aria-label="Appendix">Appendix</a><ul>
                        
                <li>
                    <a href="#a-instructgpt-automatic-evaluation-results" aria-label="A. InstructGPT automatic evaluation results">A. InstructGPT automatic evaluation results</a></li></ul>
                </li>
                <li>
                    <a href="#version-history" aria-label="Version history">Version history</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><style>
td {
  vertical-align: top;
}
figure {
    display: inline-block;
}
.screenshot {
    box-shadow: 0 0px 14px 0 rgba(0, 0, 0, 0.2), 0 6px 20px 0 rgba(0, 0, 0, 0.19);
    border-radius: 6px !important;
    padding: 8px;
    background: white;
}

.drawing {
    box-shadow: None;
    border-radius: 6px !important;
    padding: 8px;
    background: white;
}

</style>
<blockquote>
<p><em><strong>Disclaimer:</strong> This post collects some notes from exploring language model evaluation approaches in early 2023. It will (likely) be outdated by the time you read this. Improvement suggestions are welcome and can be sent to <code>contact (at) arduin.io</code>.</em></p>
</blockquote>
<h2 id="1-introduction">1. Introduction<a hidden class="anchor" aria-hidden="true" href="#1-introduction">#</a></h2>
<p><em>Language models</em> (LMs) are notoriosly difficult to evaluate. Modern LMs are used for a wide variety of complex downstream tasks, such as text translation or conversation. This diversity of tasks means that no single metric can capture overall language model performance. Even for individual tasks, it can be difficult to come up with well-setup benchmarks to measure performance. Some benchmarks have been shown to allow models to achieve top performance <em>without</em> truly mastering the underlying tasks 
  <span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group"><a href="#niven2019probingneuralnetwork"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Timothy"><span itemprop="familyName">Niven</span></span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Hung-Yu"><span itemprop="familyName">Kao</span></span>,&#32;<span itemprop="datePublished">2019</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/CreativeWork"
      data-type="paper-conference"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Niven</span>,&#32;
    <meta itemprop="givenName" content="Timothy" />
    T.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Kao</span>,&#32;
    <meta itemprop="givenName" content="Hung-Yu" />
    H.</span>
  &#32;
    (<span itemprop="datePublished">2019</span>).
  &#32;<span itemprop="name">
    <i>Probing Neural Network Comprehension of Natural Language Arguments</i></span>.
  <meta itemprop="contentLocation"
        content="Florence, Italy">&#32;
  <span itemprop="publisher" itemtype="http://schema.org/Organization" itemscope="">
    <span itemprop="name">Association for Computational Linguistics</span></span>.
  <a href="https://doi.org/10.18653/v1/P19-1459"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.18653/v1/P19-1459</a></span>

</span></span>;&#32;<span class="hugo-cite-group"><a href="#zellers2019hellaswagcanmachine"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Rowan"><span itemprop="familyName">Zellers</span></span>&#32;
                &#32;et&#32;al.,&#32;<span itemprop="datePublished">2019</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zellers</span>,&#32;
    <meta itemprop="givenName" content="Rowan" />
    R.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Holtzman</span>,&#32;
    <meta itemprop="givenName" content="Ari" />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Bisk</span>,&#32;
    <meta itemprop="givenName" content="Yonatan" />
    Y.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Farhadi</span>,&#32;
    <meta itemprop="givenName" content="Ali" />
    A.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Choi</span>,&#32;
    <meta itemprop="givenName" content="Yejin" />
    Y.</span>
  &#32;
    (<span itemprop="datePublished">2019</span>).
  &#32;<span itemprop="name">HellaSwag: Can a Machine Really Finish Your Sentence?</span>.
  <a href="https://doi.org/10.48550/arXiv.1905.07830"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.1905.07830</a></span>




</span></span>)</span>. Unintended statistical biases in the training data can allow superficial learning using (basically) just word counts &ndash; without solving the intended (more complex) linguistic task. Yet, as LMs become ever more capable and see real-world deployment, reliable and interpretable evaluation methods only become more important.</p>
<p>In this post I first go through a few examples of current <em>standard benchmarks</em> in natural language processing (NLP) to illustrate the status quo of LM evaluation. In the second part, I consider some novel approaches that have recently been proposed to better capture modern models&rsquo; capabilities.</p>
<h2 id="2-standard-benchmarks">2. Standard benchmarks<a hidden class="anchor" aria-hidden="true" href="#2-standard-benchmarks">#</a></h2>
<p>There is a vast collection of NLP benchmarks. To narrow down the scope of this post, I focus on benchmarks used to evaluate <em>InstructGPT</em> 
  <span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group"><a href="#ouyang2022traininglanguagemodels"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Long"><span itemprop="familyName">Ouyang</span></span>&#32;
                &#32;et&#32;al.,&#32;<span itemprop="datePublished">2022</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Ouyang</span>,&#32;
    <meta itemprop="givenName" content="Long" />
    L.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Wu</span>,&#32;
    <meta itemprop="givenName" content="Jeff" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Jiang</span>,&#32;
    <meta itemprop="givenName" content="Xu" />
    X.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Almeida</span>,&#32;
    <meta itemprop="givenName" content="Diogo" />
    D.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Wainwright</span>,&#32;
    <meta itemprop="givenName" content="Carroll L." />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Mishkin</span>,&#32;
    <meta itemprop="givenName" content="Pamela" />
    P.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zhang</span>,&#32;
    <meta itemprop="givenName" content="Chong" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Agarwal</span>,&#32;
    <meta itemprop="givenName" content="Sandhini" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Slama</span>,&#32;
    <meta itemprop="givenName" content="Katarina" />
    K.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Ray</span>,&#32;
    <meta itemprop="givenName" content="Alex" />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Schulman</span>,&#32;
    <meta itemprop="givenName" content="John" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Hilton</span>,&#32;
    <meta itemprop="givenName" content="Jacob" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Kelton</span>,&#32;
    <meta itemprop="givenName" content="Fraser" />
    F.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Miller</span>,&#32;
    <meta itemprop="givenName" content="Luke" />
    L.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Simens</span>,&#32;
    <meta itemprop="givenName" content="Maddie" />
    M.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Askell</span>,&#32;
    <meta itemprop="givenName" content="Amanda" />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Welinder</span>,&#32;
    <meta itemprop="givenName" content="Peter" />
    P.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Christiano</span>,&#32;
    <meta itemprop="givenName" content="Paul" />
    P.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Leike</span>,&#32;
    <meta itemprop="givenName" content="Jan" />
    J.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lowe</span>,&#32;
    <meta itemprop="givenName" content="Ryan" />
    R.</span>
  &#32;
    (<span itemprop="datePublished">2022</span>).
  &#32;<span itemprop="name">Training language models to follow instructions with human feedback</span>.&#32;Retrieved from&#32;
  <a href="http://arxiv.org/abs/2203.02155"
     itemprop="identifier"
     itemtype="https://schema.org/URL">http://arxiv.org/abs/2203.02155</a></span>




</span></span>)</span> (closely related to OpenAI&rsquo;s <a href="https://openai.com/blog/chatgpt"><em>ChatGPT</em></a> models) as illustrative examples. The aim behind InstructGPT (and related large language models) is to provide a multi-purpose model that can be used for a diverse set of downstream tasks. This diversity is also reflected in the kind of benchmarks these models are tested on. In this post, I only consider examples of scalable evaluation methods that <em>do not</em> require direct human feedback.</p>
<p>Standard benchmarks can be split into two categories: <em>task-specific</em> and <em>alignment</em> benchmarks. Task-specific benchmarks attempt to evaluate the models ability to perform specific tasks, such as translation or discrete reasoning. Each benchmark typically covers one such task. Alignment benchmarks cover additional text charateristics we would like our LM output to have, such as <em>not being racist</em> or <em>being unbiased</em>. These additional characteristics can be more difficult to rigorously define and test for. Nevertheless, these characteristics are very important for deploying LMs safely. The figure below provides an overview of standard NLP benchmarks.



<figure style="text-align: center;"><img class="drawing"
         src="nlp_benchmark_overview.png" width="100%"style="display:inline"
    /><figcaption>
        <p align="center">Overview of NLP benchmarks.</p>
    </figcaption>
</figure></p>
<h3 id="task-specific-benchmarks">Task-specific benchmarks<a hidden class="anchor" aria-hidden="true" href="#task-specific-benchmarks">#</a></h3>
<p>Below is a list of some of the task-specific benchmarks used for InstructGPT.</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>SQuAD</strong><br>
  <span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group"><a href="#rajpurkar2018knowwhatyou"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Pranav"><span itemprop="familyName">Rajpurkar</span></span>&#32;
                &#32;et&#32;al.,&#32;<span itemprop="datePublished">2018</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Rajpurkar</span>,&#32;
    <meta itemprop="givenName" content="Pranav" />
    P.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Jia</span>,&#32;
    <meta itemprop="givenName" content="Robin" />
    R.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Liang</span>,&#32;
    <meta itemprop="givenName" content="Percy" />
    P.</span>
  &#32;
    (<span itemprop="datePublished">2018</span>).
  &#32;<span itemprop="name">Know What You Don&rsquo;t Know: Unanswerable Questions for SQuAD</span>.
  <a href="https://doi.org/10.48550/arXiv.1806.03822"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.1806.03822</a></span>




</span></span>)</span></td>
<td>The <em>Stanford Question Answering Dataset</em> (SQuAD) v2.0 consists of a large corpus of small text excerpts from Wikipedia articles (100,000+). Each text has corresponding questions and anwers created by crowdworkers. The original SQuAD v1.0 
  <span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group"><a href="#rajpurkar2016squad100000"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Pranav"><span itemprop="familyName">Rajpurkar</span></span>&#32;
                &#32;et&#32;al.,&#32;<span itemprop="datePublished">2016</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Rajpurkar</span>,&#32;
    <meta itemprop="givenName" content="Pranav" />
    P.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zhang</span>,&#32;
    <meta itemprop="givenName" content="Jian" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lopyrev</span>,&#32;
    <meta itemprop="givenName" content="Konstantin" />
    K.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Liang</span>,&#32;
    <meta itemprop="givenName" content="Percy" />
    P.</span>
  &#32;
    (<span itemprop="datePublished">2016</span>).
  &#32;<span itemprop="name">SQuAD: 100,000+ Questions for Machine Comprehension of Text</span>.
  <a href="https://doi.org/10.48550/arXiv.1606.05250"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.1606.05250</a></span>




</span></span>)</span> was improved in v2.0 to include unanswerable questions. See example questions from both papers below. <br>


<figure style="text-align: center;"><img class="screenshot"
         src="example_squadv1.png" width="250"style="display:inline"
    /><figcaption>
        <p align="center">Answerable questions (v1.0). <br/> Figure from 
  <span class="hugo-cite-intext"
        itemprop="citation"><span class="hugo-cite-group"><a href="#rajpurkar2016squad100000"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Pranav"><span itemprop="familyName">Rajpurkar</span></span>&#32;
                &#32;et&#32;al.&#32;(<span itemprop="datePublished">2016</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Rajpurkar</span>,&#32;
    <meta itemprop="givenName" content="Pranav" />
    P.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zhang</span>,&#32;
    <meta itemprop="givenName" content="Jian" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lopyrev</span>,&#32;
    <meta itemprop="givenName" content="Konstantin" />
    K.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Liang</span>,&#32;
    <meta itemprop="givenName" content="Percy" />
    P.</span>
  &#32;
    (<span itemprop="datePublished">2016</span>).
  &#32;<span itemprop="name">SQuAD: 100,000+ Questions for Machine Comprehension of Text</span>.
  <a href="https://doi.org/10.48550/arXiv.1606.05250"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.1606.05250</a></span>




</span></span>)</span>. </p>
    </figcaption>
</figure>   


<figure style="text-align: center;"><img class="screenshot"
         src="example_squadv2.png" width="250"style="display:inline"
    /><figcaption>
        <p align="center"> Unanswerable questions (v2.0). <br/> Figure from 
  <span class="hugo-cite-intext"
        itemprop="citation"><span class="hugo-cite-group"><a href="#rajpurkar2018knowwhatyou"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Pranav"><span itemprop="familyName">Rajpurkar</span></span>&#32;
                &#32;et&#32;al.&#32;(<span itemprop="datePublished">2018</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Rajpurkar</span>,&#32;
    <meta itemprop="givenName" content="Pranav" />
    P.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Jia</span>,&#32;
    <meta itemprop="givenName" content="Robin" />
    R.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Liang</span>,&#32;
    <meta itemprop="givenName" content="Percy" />
    P.</span>
  &#32;
    (<span itemprop="datePublished">2018</span>).
  &#32;<span itemprop="name">Know What You Don&rsquo;t Know: Unanswerable Questions for SQuAD</span>.
  <a href="https://doi.org/10.48550/arXiv.1806.03822"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.1806.03822</a></span>




</span></span>)</span>. </p>
    </figcaption>
</figure></td>
</tr>
<tr>
<td><strong>DROP</strong><br>
  <span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group"><a href="#dua2019dropreadingcomprehension"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Dheeru"><span itemprop="familyName">Dua</span></span>&#32;
                &#32;et&#32;al.,&#32;<span itemprop="datePublished">2019</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Dua</span>,&#32;
    <meta itemprop="givenName" content="Dheeru" />
    D.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Wang</span>,&#32;
    <meta itemprop="givenName" content="Yizhong" />
    Y.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Dasigi</span>,&#32;
    <meta itemprop="givenName" content="Pradeep" />
    P.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Stanovsky</span>,&#32;
    <meta itemprop="givenName" content="Gabriel" />
    G.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Singh</span>,&#32;
    <meta itemprop="givenName" content="Sameer" />
    S.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Gardner</span>,&#32;
    <meta itemprop="givenName" content="Matt" />
    M.</span>
  &#32;
    (<span itemprop="datePublished">2019</span>).
  &#32;<span itemprop="name">DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs</span>.
  <a href="https://doi.org/10.48550/arXiv.1903.00161"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.1903.00161</a></span>




</span></span>)</span></td>
<td>The DROP dataset aims to assess models&rsquo; ability in <em>discrete reasoning over text in a paragraph</em> (DROP). The dataset consists of 96,000 questions. Given a passage of text, the model is given a question that requires reasoning using discrete operations such as addition, counting, or sorting. See example questions below. <br>


<figure style="text-align: center;"><img class="screenshot"
         src="example_drop.png" width="100%"style="display:inline"
    /><figcaption>
        <p align="center"> Top four reasoning operation example. Figure from 
  <span class="hugo-cite-intext"
        itemprop="citation"><span class="hugo-cite-group"><a href="#dua2019dropreadingcomprehension"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Dheeru"><span itemprop="familyName">Dua</span></span>&#32;
                &#32;et&#32;al.&#32;(<span itemprop="datePublished">2019</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Dua</span>,&#32;
    <meta itemprop="givenName" content="Dheeru" />
    D.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Wang</span>,&#32;
    <meta itemprop="givenName" content="Yizhong" />
    Y.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Dasigi</span>,&#32;
    <meta itemprop="givenName" content="Pradeep" />
    P.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Stanovsky</span>,&#32;
    <meta itemprop="givenName" content="Gabriel" />
    G.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Singh</span>,&#32;
    <meta itemprop="givenName" content="Sameer" />
    S.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Gardner</span>,&#32;
    <meta itemprop="givenName" content="Matt" />
    M.</span>
  &#32;
    (<span itemprop="datePublished">2019</span>).
  &#32;<span itemprop="name">DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs</span>.
  <a href="https://doi.org/10.48550/arXiv.1903.00161"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.1903.00161</a></span>




</span></span>)</span>.</p>
    </figcaption>
</figure></td>
</tr>
<tr>
<td><strong>HellaSwag</strong><br>
  <span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group"><a href="#zellers2019hellaswagcanmachine"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Rowan"><span itemprop="familyName">Zellers</span></span>&#32;
                &#32;et&#32;al.,&#32;<span itemprop="datePublished">2019</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zellers</span>,&#32;
    <meta itemprop="givenName" content="Rowan" />
    R.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Holtzman</span>,&#32;
    <meta itemprop="givenName" content="Ari" />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Bisk</span>,&#32;
    <meta itemprop="givenName" content="Yonatan" />
    Y.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Farhadi</span>,&#32;
    <meta itemprop="givenName" content="Ali" />
    A.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Choi</span>,&#32;
    <meta itemprop="givenName" content="Yejin" />
    Y.</span>
  &#32;
    (<span itemprop="datePublished">2019</span>).
  &#32;<span itemprop="name">HellaSwag: Can a Machine Really Finish Your Sentence?</span>.
  <a href="https://doi.org/10.48550/arXiv.1905.07830"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.1905.07830</a></span>




</span></span>)</span></td>
<td>The HellaSwag dataset consists of 70,000 questions attempting to evaluate the commonsense natural language inference ability of a model. Given a text fragment referred to as <em>context</em>, the model is asked to select the most plausible of multiple possible endings. HellaSwag is an extension of the SWAG data set by 
  <span class="hugo-cite-intext"
        itemprop="citation"><span class="hugo-cite-group"><a href="#zellers2018swaglargescaleadversarial"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Rowan"><span itemprop="familyName">Zellers</span></span>&#32;
                &#32;et&#32;al.&#32;(<span itemprop="datePublished">2018</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zellers</span>,&#32;
    <meta itemprop="givenName" content="Rowan" />
    R.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Bisk</span>,&#32;
    <meta itemprop="givenName" content="Yonatan" />
    Y.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Schwartz</span>,&#32;
    <meta itemprop="givenName" content="Roy" />
    R.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Choi</span>,&#32;
    <meta itemprop="givenName" content="Yejin" />
    Y.</span>
  &#32;
    (<span itemprop="datePublished">2018</span>).
  &#32;<span itemprop="name">SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference</span>.
  <a href="https://doi.org/10.48550/arXiv.1808.05326"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.1808.05326</a></span>




</span></span>)</span>. In addition to the text data from video captioning used in SWAG, HellaSwag adds text data from <a href="https://www.wikihow.com/">WikiHow</a>. Both datasets use <em>adverserial filtering</em> to address the issue of <em>annotation artifacts</em>, where human labellers leave unintended biases in wrong labels. During the data generation a generator and a discriminator model are jointly used to filter out endings that are too easy to distinguish. With this iterative process, this data set provides a template how to come up with more challenging data sets for ever more capable language models. <br><center>


<figure style="text-align: center;"><img class="screenshot"
         src="example_hellaswag.png" width="400"style="display:inline"
    /><figcaption>
        <p align="center"> Example question answered by a BERT model, once correct (blue) and once incorrect (red). The bold text indicates the correct answer. Figure from 
  <span class="hugo-cite-intext"
        itemprop="citation"><span class="hugo-cite-group"><a href="#zellers2019hellaswagcanmachine"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Rowan"><span itemprop="familyName">Zellers</span></span>&#32;
                &#32;et&#32;al.&#32;(<span itemprop="datePublished">2019</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zellers</span>,&#32;
    <meta itemprop="givenName" content="Rowan" />
    R.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Holtzman</span>,&#32;
    <meta itemprop="givenName" content="Ari" />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Bisk</span>,&#32;
    <meta itemprop="givenName" content="Yonatan" />
    Y.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Farhadi</span>,&#32;
    <meta itemprop="givenName" content="Ali" />
    A.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Choi</span>,&#32;
    <meta itemprop="givenName" content="Yejin" />
    Y.</span>
  &#32;
    (<span itemprop="datePublished">2019</span>).
  &#32;<span itemprop="name">HellaSwag: Can a Machine Really Finish Your Sentence?</span>.
  <a href="https://doi.org/10.48550/arXiv.1905.07830"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.1905.07830</a></span>




</span></span>)</span>.</p>
    </figcaption>
</figure></center></td>
</tr>
<tr>
<td><strong>WMT 2015 French to English translation</strong><br>
  <span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group"><a href="#bojar2015findings2015workshop"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Ondrej"><span itemprop="familyName">Bojar</span></span>&#32;
                &#32;et&#32;al.,&#32;<span itemprop="datePublished">2015</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Bojar</span>,&#32;
    <meta itemprop="givenName" content="Ondrej" />
    O.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Chatterjee</span>,&#32;
    <meta itemprop="givenName" content="Rajen" />
    R.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Federmann</span>,&#32;
    <meta itemprop="givenName" content="Christian" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Haddow</span>,&#32;
    <meta itemprop="givenName" content="Barry" />
    B.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Huck</span>,&#32;
    <meta itemprop="givenName" content="Matthias" />
    M.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Hokamp</span>,&#32;
    <meta itemprop="givenName" content="Chris" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Koehn</span>,&#32;
    <meta itemprop="givenName" content="Philipp" />
    P.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Logacheva</span>,&#32;
    <meta itemprop="givenName" content="Varvara" />
    V.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Monz</span>,&#32;
    <meta itemprop="givenName" content="Christof" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Negri</span>,&#32;
    <meta itemprop="givenName" content="Matteo" />
    M.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Post</span>,&#32;
    <meta itemprop="givenName" content="Matt" />
    M.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Scarton</span>,&#32;
    <meta itemprop="givenName" content="Carolina" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Specia</span>,&#32;
    <meta itemprop="givenName" content="Lucia" />
    L.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Turchi</span>,&#32;
    <meta itemprop="givenName" content="Marco" />
    M.</span>
  &#32;
    (<span itemprop="datePublished">2015</span>).
  &#32;<span itemprop="name">Findings of the 2015 Workshop on Statistical Machine Translation</span>.<i>
    <span itemprop="about">Proceedings of the Tenth Workshop on Statistical Machine Translation</span></i>.&#32;<span itemprop="pagination">1–46</span>.&#32;Retrieved from&#32;
  <a href="https://www.research.ed.ac.uk/en/publications/findings-of-the-2015-workshop-on-statistical-machine-translation"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://www.research.ed.ac.uk/en/publications/findings-of-the-2015-workshop-on-statistical-machine-translation</a></span>




</span></span>)</span></td>
<td>A dataset challenges a model to translate from french text to english text. In the original workshop, models were evaluated using human annotators that make a pairwise comparison of the translation of the same text by different systems. For purpose of evaluating InstructGPT instead of the human evaluation the automatic translation quality score BLEU 
  <span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group"><a href="#papineni2002bleumethodautomatic"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Kishore"><span itemprop="familyName">Papineni</span></span>&#32;
                &#32;et&#32;al.,&#32;<span itemprop="datePublished">2002</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/CreativeWork"
      data-type="paper-conference"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Papineni</span>,&#32;
    <meta itemprop="givenName" content="Kishore" />
    K.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Roukos</span>,&#32;
    <meta itemprop="givenName" content="Salim" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Ward</span>,&#32;
    <meta itemprop="givenName" content="Todd" />
    T.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zhu</span>,&#32;
    <meta itemprop="givenName" content="Wei-Jing" />
    W.</span>
  &#32;
    (<span itemprop="datePublished">2002</span>).
  &#32;<span itemprop="name">
    <i>BLEU: a method for automatic evaluation of machine translation</i></span>.
  </span>

</span></span>)</span> was used.  <br><center>


<figure style="text-align: center;"><img class="screenshot"
         src="example_wmt2015.png" width="400"style="display:inline"
    /><figcaption>
        <p align="center">Screenshot of human evaluation interface with example translation task from Russian to English. Figure from 
  <span class="hugo-cite-intext"
        itemprop="citation"><span class="hugo-cite-group"><a href="#bojar2015findings2015workshop"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Ondrej"><span itemprop="familyName">Bojar</span></span>&#32;
                &#32;et&#32;al.&#32;(<span itemprop="datePublished">2015</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Bojar</span>,&#32;
    <meta itemprop="givenName" content="Ondrej" />
    O.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Chatterjee</span>,&#32;
    <meta itemprop="givenName" content="Rajen" />
    R.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Federmann</span>,&#32;
    <meta itemprop="givenName" content="Christian" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Haddow</span>,&#32;
    <meta itemprop="givenName" content="Barry" />
    B.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Huck</span>,&#32;
    <meta itemprop="givenName" content="Matthias" />
    M.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Hokamp</span>,&#32;
    <meta itemprop="givenName" content="Chris" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Koehn</span>,&#32;
    <meta itemprop="givenName" content="Philipp" />
    P.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Logacheva</span>,&#32;
    <meta itemprop="givenName" content="Varvara" />
    V.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Monz</span>,&#32;
    <meta itemprop="givenName" content="Christof" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Negri</span>,&#32;
    <meta itemprop="givenName" content="Matteo" />
    M.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Post</span>,&#32;
    <meta itemprop="givenName" content="Matt" />
    M.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Scarton</span>,&#32;
    <meta itemprop="givenName" content="Carolina" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Specia</span>,&#32;
    <meta itemprop="givenName" content="Lucia" />
    L.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Turchi</span>,&#32;
    <meta itemprop="givenName" content="Marco" />
    M.</span>
  &#32;
    (<span itemprop="datePublished">2015</span>).
  &#32;<span itemprop="name">Findings of the 2015 Workshop on Statistical Machine Translation</span>.<i>
    <span itemprop="about">Proceedings of the Tenth Workshop on Statistical Machine Translation</span></i>.&#32;<span itemprop="pagination">1–46</span>.&#32;Retrieved from&#32;
  <a href="https://www.research.ed.ac.uk/en/publications/findings-of-the-2015-workshop-on-statistical-machine-translation"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://www.research.ed.ac.uk/en/publications/findings-of-the-2015-workshop-on-statistical-machine-translation</a></span>




</span></span>)</span>.</p>
    </figcaption>
</figure></center></td>
</tr>
</tbody>
</table>
<p><br/><br/></p>
<h3 id="alignment-benchmarks">Alignment benchmarks<a hidden class="anchor" aria-hidden="true" href="#alignment-benchmarks">#</a></h3>
<p>In addition to solving a primary task like creating good autocomplete suggestions, we likely also want to make sure that the generated text is not racist or insulting. A number of dedicated benchmarks were created to address these secondary <em>human alignment</em> considerations.</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>RealToxicityPrompts</strong><br>
  <span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group"><a href="#gehman2020realtoxicitypromptsevaluatingneural"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Samuel"><span itemprop="familyName">Gehman</span></span>&#32;
                &#32;et&#32;al.,&#32;<span itemprop="datePublished">2020</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Gehman</span>,&#32;
    <meta itemprop="givenName" content="Samuel" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Gururangan</span>,&#32;
    <meta itemprop="givenName" content="Suchin" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Sap</span>,&#32;
    <meta itemprop="givenName" content="Maarten" />
    M.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Choi</span>,&#32;
    <meta itemprop="givenName" content="Yejin" />
    Y.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Smith</span>,&#32;
    <meta itemprop="givenName" content="Noah A." />
    N.</span>
  &#32;
    (<span itemprop="datePublished">2020</span>).
  &#32;<span itemprop="name">RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models</span>.
  <a href="https://doi.org/10.48550/arXiv.2009.11462"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.2009.11462</a></span>




</span></span>)</span></td>
<td>RealToxicityPrompts consists of 100,000 partial sentences that, when comleted by an LM, may result in racist, sexist or otherwise toxic language. The prompts are given to the LM in a conditional language generation (or auto complete) task. The <a href="https://www.perspectiveapi.com/">Perspective API</a> is used to evaluate the toxicity. The use of this external API as a black-box evaluation method means that the results may not be reproducible - as the API&rsquo;s output may change or be discontinued. More generally, as the authors point out, current methods are unable to adapt an LM to <em>never</em> say toxic things. This limitations presents serious challenges for the safe deployment of LM-based applications. <br><center>


<figure style="text-align: center;"><img class="screenshot"
         src="example_realtoxicprompts.png" width="340"style="display:inline"
    /><figcaption>
        <p align="center">Prompts from the RealToxicityPrompts data set. Figure from 
  <span class="hugo-cite-intext"
        itemprop="citation"><span class="hugo-cite-group"><a href="#gehman2020realtoxicitypromptsevaluatingneural"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Samuel"><span itemprop="familyName">Gehman</span></span>&#32;
                &#32;et&#32;al.&#32;(<span itemprop="datePublished">2020</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Gehman</span>,&#32;
    <meta itemprop="givenName" content="Samuel" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Gururangan</span>,&#32;
    <meta itemprop="givenName" content="Suchin" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Sap</span>,&#32;
    <meta itemprop="givenName" content="Maarten" />
    M.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Choi</span>,&#32;
    <meta itemprop="givenName" content="Yejin" />
    Y.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Smith</span>,&#32;
    <meta itemprop="givenName" content="Noah A." />
    N.</span>
  &#32;
    (<span itemprop="datePublished">2020</span>).
  &#32;<span itemprop="name">RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models</span>.
  <a href="https://doi.org/10.48550/arXiv.2009.11462"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.2009.11462</a></span>




</span></span>)</span>.</p>
    </figcaption>
</figure></center></td>
</tr>
<tr>
<td><strong>Winogender</strong><br>
  <span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group"><a href="#rudinger2018genderbiascoreference"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Rachel"><span itemprop="familyName">Rudinger</span></span>&#32;
                &#32;et&#32;al.,&#32;<span itemprop="datePublished">2018</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Rudinger</span>,&#32;
    <meta itemprop="givenName" content="Rachel" />
    R.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Naradowsky</span>,&#32;
    <meta itemprop="givenName" content="Jason" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Leonard</span>,&#32;
    <meta itemprop="givenName" content="Brian" />
    B.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Van Durme</span>,&#32;
    <meta itemprop="givenName" content="Benjamin" />
    B.</span>
  &#32;
    (<span itemprop="datePublished">2018</span>).
  &#32;<span itemprop="name">Gender Bias in Coreference Resolution</span>.
  <a href="https://doi.org/10.48550/arXiv.1804.09301"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.1804.09301</a></span>




</span></span>)</span></td>
<td>The Winogender data set aims to detect gender bias in language models. The data set consists of a number of similar sentences that reference occupations and their gender. For the evaluation of InstructGPT (as far as I understand it), pairs of the sentences that only vary in gender were considered. Then the relative probability of produce one of the sentences was computed, to see for example if the model thought paramedics are more likely to be male.<br><center>


<figure style="text-align: center;"><img class="screenshot"
         src="example_winogender.png" width="300"style="display:inline"
    /><figcaption>
        <p align="center">Winogender example. Figure from 
  <span class="hugo-cite-intext"
        itemprop="citation"><span class="hugo-cite-group"><a href="#rudinger2018genderbiascoreference"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Rachel"><span itemprop="familyName">Rudinger</span></span>&#32;
                &#32;et&#32;al.&#32;(<span itemprop="datePublished">2018</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Rudinger</span>,&#32;
    <meta itemprop="givenName" content="Rachel" />
    R.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Naradowsky</span>,&#32;
    <meta itemprop="givenName" content="Jason" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Leonard</span>,&#32;
    <meta itemprop="givenName" content="Brian" />
    B.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Van Durme</span>,&#32;
    <meta itemprop="givenName" content="Benjamin" />
    B.</span>
  &#32;
    (<span itemprop="datePublished">2018</span>).
  &#32;<span itemprop="name">Gender Bias in Coreference Resolution</span>.
  <a href="https://doi.org/10.48550/arXiv.1804.09301"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.1804.09301</a></span>




</span></span>)</span>.</p>
    </figcaption>
</figure></center></td>
</tr>
<tr>
<td><strong>CrowS-Pairs</strong><br>
  <span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group"><a href="#nangia2020crowspairschallengedataset"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Nikita"><span itemprop="familyName">Nangia</span></span>&#32;
                &#32;et&#32;al.,&#32;<span itemprop="datePublished">2020</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Nangia</span>,&#32;
    <meta itemprop="givenName" content="Nikita" />
    N.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Vania</span>,&#32;
    <meta itemprop="givenName" content="Clara" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Bhalerao</span>,&#32;
    <meta itemprop="givenName" content="Rasika" />
    R.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Bowman</span>,&#32;
    <meta itemprop="givenName" content="Samuel R." />
    S.</span>
  &#32;
    (<span itemprop="datePublished">2020</span>).
  &#32;<span itemprop="name">CrowS-Pairs: A Challenge Dataset for Measuring Social Biases in Masked Language Models</span>.
  <a href="https://doi.org/10.48550/arXiv.2010.00133"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.2010.00133</a></span>




</span></span>)</span></td>
<td>The CrowS-Pairs dataset consists of 1508 pairs of sentences, each with one more stereotyping than the other. The pairs cover various bias including race, religion and age. In the context of InstructGPT, the dataset is used similarly to Winogender: the probability of computing the more stereotyping sentence is computed. <br><center>


<figure style="text-align: center;"><img class="screenshot"
         src="example_crowspairs.png" width="100%"style="display:inline"
    /><figcaption>
        <p align="center">CrowS-Pairs. Figure from 
  <span class="hugo-cite-intext"
        itemprop="citation"><span class="hugo-cite-group"><a href="#nangia2020crowspairschallengedataset"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Nikita"><span itemprop="familyName">Nangia</span></span>&#32;
                &#32;et&#32;al.&#32;(<span itemprop="datePublished">2020</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Nangia</span>,&#32;
    <meta itemprop="givenName" content="Nikita" />
    N.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Vania</span>,&#32;
    <meta itemprop="givenName" content="Clara" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Bhalerao</span>,&#32;
    <meta itemprop="givenName" content="Rasika" />
    R.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Bowman</span>,&#32;
    <meta itemprop="givenName" content="Samuel R." />
    S.</span>
  &#32;
    (<span itemprop="datePublished">2020</span>).
  &#32;<span itemprop="name">CrowS-Pairs: A Challenge Dataset for Measuring Social Biases in Masked Language Models</span>.
  <a href="https://doi.org/10.48550/arXiv.2010.00133"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.2010.00133</a></span>




</span></span>)</span>.</p>
    </figcaption>
</figure></center></td>
</tr>
<tr>
<td><strong>TruthfulQA</strong><br>
  <span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group"><a href="#lin2022truthfulqameasuringhow"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Stephanie"><span itemprop="familyName">Lin</span></span>&#32;
                &#32;et&#32;al.,&#32;<span itemprop="datePublished">2022</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lin</span>,&#32;
    <meta itemprop="givenName" content="Stephanie" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Hilton</span>,&#32;
    <meta itemprop="givenName" content="Jacob" />
    J.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Evans</span>,&#32;
    <meta itemprop="givenName" content="Owain" />
    O.</span>
  &#32;
    (<span itemprop="datePublished">2022</span>).
  &#32;<span itemprop="name">TruthfulQA: Measuring How Models Mimic Human Falsehoods</span>.
  <a href="https://doi.org/10.48550/arXiv.2109.07958"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.2109.07958</a></span>




</span></span>)</span></td>
<td>The TruthfulQA benchmark consists of 817 questions, each crafted such that some humans might answer them incorrectly due to misconceptions. The authors used both human and automated evaluation to assess the truthfullness of model answers. They demonstrated that a finetuned GPT-3 model was 90-96% accurate in detecting truthfulness of answers by other models. <br><center>


<figure style="text-align: center;"><img class="screenshot"
         src="example_truthfulqa.png" width="350"style="display:inline"
    /><figcaption>
        <p align="center">TruthfulQA examples. Figure from 
  <span class="hugo-cite-intext"
        itemprop="citation"><span class="hugo-cite-group"><a href="#lin2022truthfulqameasuringhow"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Stephanie"><span itemprop="familyName">Lin</span></span>&#32;
                &#32;et&#32;al.&#32;(<span itemprop="datePublished">2022</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lin</span>,&#32;
    <meta itemprop="givenName" content="Stephanie" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Hilton</span>,&#32;
    <meta itemprop="givenName" content="Jacob" />
    J.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Evans</span>,&#32;
    <meta itemprop="givenName" content="Owain" />
    O.</span>
  &#32;
    (<span itemprop="datePublished">2022</span>).
  &#32;<span itemprop="name">TruthfulQA: Measuring How Models Mimic Human Falsehoods</span>.
  <a href="https://doi.org/10.48550/arXiv.2109.07958"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.2109.07958</a></span>




</span></span>)</span>.</p>
    </figcaption>
</figure></center></td>
</tr>
</tbody>
</table>
<p>In addition to the benchmarks described above, InstructGPT was also evaluated on the following benchmarks: SST
  <span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group"><a href="#socher2013recursivedeepmodels"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Richard"><span itemprop="familyName">Socher</span></span>&#32;
                &#32;et&#32;al.,&#32;<span itemprop="datePublished">2013</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/CreativeWork"
      data-type="paper-conference"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Socher</span>,&#32;
    <meta itemprop="givenName" content="Richard" />
    R.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Perelygin</span>,&#32;
    <meta itemprop="givenName" content="Alex" />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Wu</span>,&#32;
    <meta itemprop="givenName" content="Jean" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Chuang</span>,&#32;
    <meta itemprop="givenName" content="Jason" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Manning</span>,&#32;
    <meta itemprop="givenName" content="Christopher D." />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Ng</span>,&#32;
    <meta itemprop="givenName" content="Andrew Y." />
    A.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Potts</span>,&#32;
    <meta itemprop="givenName" content="Christopher" />
    C.</span>
  &#32;
    (<span itemprop="datePublished">2013</span>).
  &#32;<span itemprop="name">
    <i>Recursive deep models for semantic compositionality over a sentiment treebank</i></span>.
  </span>

</span></span>)</span>, RTE and WSC parts of SuperGLUE 
  <span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group"><a href="#wang2019supergluestickierbenchmark"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Alex"><span itemprop="familyName">Wang</span></span>&#32;
                &#32;et&#32;al.,&#32;<span itemprop="datePublished">2019</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/CreativeWork"
      data-type="paper-conference"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Wang</span>,&#32;
    <meta itemprop="givenName" content="Alex" />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Pruksachatkun</span>,&#32;
    <meta itemprop="givenName" content="Yada" />
    Y.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Nangia</span>,&#32;
    <meta itemprop="givenName" content="Nikita" />
    N.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Singh</span>,&#32;
    <meta itemprop="givenName" content="Amanpreet" />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Michael</span>,&#32;
    <meta itemprop="givenName" content="Julian" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Hill</span>,&#32;
    <meta itemprop="givenName" content="Felix" />
    F.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Levy</span>,&#32;
    <meta itemprop="givenName" content="Omer" />
    O.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Bowman</span>,&#32;
    <meta itemprop="givenName" content="Samuel" />
    S.</span>
  &#32;
    (<span itemprop="datePublished">2019</span>).
  &#32;<span itemprop="name">
    <i>SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems</i></span>.
  &#32;
  <span itemprop="publisher" itemtype="http://schema.org/Organization" itemscope="">
    <span itemprop="name">Curran Associates, Inc.</span></span>.&#32;Retrieved from&#32;
  <a href="https://proceedings.neurips.cc/paper/2019/hash/4496bf24afe7fab6f046bf4923da8de6-Abstract.html"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://proceedings.neurips.cc/paper/2019/hash/4496bf24afe7fab6f046bf4923da8de6-Abstract.html</a></span>

</span></span>)</span>, CNN/Daily Mail Summarization 
  <span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group"><a href="#nallapati2016abstractivetextsummarization"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Ramesh"><span itemprop="familyName">Nallapati</span></span>&#32;
                &#32;et&#32;al.,&#32;<span itemprop="datePublished">2016</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Nallapati</span>,&#32;
    <meta itemprop="givenName" content="Ramesh" />
    R.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zhou</span>,&#32;
    <meta itemprop="givenName" content="Bowen" />
    B.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">santos</span>,&#32;
    <meta itemprop="givenName" content="Cicero Nogueira" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Gulcehre</span>,&#32;
    <meta itemprop="givenName" content="Caglar" />
    C.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Xiang</span>,&#32;
    <meta itemprop="givenName" content="Bing" />
    B.</span>
  &#32;
    (<span itemprop="datePublished">2016</span>).
  &#32;<span itemprop="name">Abstractive Text Summarization Using Sequence-to-Sequence RNNs and Beyond</span>.
  <a href="https://doi.org/10.48550/arXiv.1602.06023"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.1602.06023</a></span>




</span></span>)</span>, and Reddit TLDR Summarization 
  <span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group"><a href="#volske2017tldrmining"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Michael"><span itemprop="familyName">Völske</span></span>&#32;
                &#32;et&#32;al.,&#32;<span itemprop="datePublished">2017</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/CreativeWork"
      data-type="paper-conference"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Völske</span>,&#32;
    <meta itemprop="givenName" content="Michael" />
    M.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Potthast</span>,&#32;
    <meta itemprop="givenName" content="Martin" />
    M.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Syed</span>,&#32;
    <meta itemprop="givenName" content="Shahbaz" />
    S.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Stein</span>,&#32;
    <meta itemprop="givenName" content="Benno" />
    B.</span>
  &#32;
    (<span itemprop="datePublished">2017</span>).
  &#32;<span itemprop="name">
    <i>Tl; dr: Mining reddit to learn automatic summarization</i></span>.
  </span>

</span></span>)</span>. Further, there is a large number of additional benchmarks that were not considered for InstructGPT. For examples see the <a href="https://github.com/EleutherAI/lm-evaluation-harness/blob/master/docs/task_table.md">list of 200+ benchmarks</a> available in the <a href="https://github.com/EleutherAI/lm-evaluation-harness/">lm-evaluation-harness</a> by <a href="https://www.eleuther.ai/">EleutherAI</a>.</p>
<h2 id="3-novel-benchmarks">3. Novel Benchmarks<a hidden class="anchor" aria-hidden="true" href="#3-novel-benchmarks">#</a></h2>
<h3 id="lm-generated-benchmarks">LM-generated benchmarks<a hidden class="anchor" aria-hidden="true" href="#lm-generated-benchmarks">#</a></h3>
<p>
  <span class="hugo-cite-intext"
        itemprop="citation"><span class="hugo-cite-group"><a href="#perez2022discoveringlanguagemodel"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Ethan"><span itemprop="familyName">Perez</span></span>&#32;
                &#32;et&#32;al.&#32;(<span itemprop="datePublished">2022</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Perez</span>,&#32;
    <meta itemprop="givenName" content="Ethan" />
    E.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"></span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lukošiūtė</span>,&#32;
    <meta itemprop="givenName" content="Kamilė" />
    K.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Nguyen</span>,&#32;
    <meta itemprop="givenName" content="Karina" />
    K.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Chen</span>,&#32;
    <meta itemprop="givenName" content="Edwin" />
    E.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Heiner</span>,&#32;
    <meta itemprop="givenName" content="Scott" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Pettit</span>,&#32;
    <meta itemprop="givenName" content="Craig" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Olsson</span>,&#32;
    <meta itemprop="givenName" content="Catherine" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Kundu</span>,&#32;
    <meta itemprop="givenName" content="Sandipan" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Kadavath</span>,&#32;
    <meta itemprop="givenName" content="Saurav" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Jones</span>,&#32;
    <meta itemprop="givenName" content="Andy" />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Chen</span>,&#32;
    <meta itemprop="givenName" content="Anna" />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Mann</span>,&#32;
    <meta itemprop="givenName" content="Ben" />
    B.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Israel</span>,&#32;
    <meta itemprop="givenName" content="Brian" />
    B.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Seethor</span>,&#32;
    <meta itemprop="givenName" content="Bryan" />
    B.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">McKinnon</span>,&#32;
    <meta itemprop="givenName" content="Cameron" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Olah</span>,&#32;
    <meta itemprop="givenName" content="Christopher" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Yan</span>,&#32;
    <meta itemprop="givenName" content="Da" />
    D.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Amodei</span>,&#32;
    <meta itemprop="givenName" content="Daniela" />
    D.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Amodei</span>,&#32;
    <meta itemprop="givenName" content="Dario" />
    D.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Drain</span>,&#32;
    <meta itemprop="givenName" content="Dawn" />
    D.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Li</span>,&#32;
    <meta itemprop="givenName" content="Dustin" />
    D.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Tran-Johnson</span>,&#32;
    <meta itemprop="givenName" content="Eli" />
    E.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Khundadze</span>,&#32;
    <meta itemprop="givenName" content="Guro" />
    G.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Kernion</span>,&#32;
    <meta itemprop="givenName" content="Jackson" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Landis</span>,&#32;
    <meta itemprop="givenName" content="James" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Kerr</span>,&#32;
    <meta itemprop="givenName" content="Jamie" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Mueller</span>,&#32;
    <meta itemprop="givenName" content="Jared" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Hyun</span>,&#32;
    <meta itemprop="givenName" content="Jeeyoon" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Landau</span>,&#32;
    <meta itemprop="givenName" content="Joshua" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Ndousse</span>,&#32;
    <meta itemprop="givenName" content="Kamal" />
    K.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Goldberg</span>,&#32;
    <meta itemprop="givenName" content="Landon" />
    L.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lovitt</span>,&#32;
    <meta itemprop="givenName" content="Liane" />
    L.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lucas</span>,&#32;
    <meta itemprop="givenName" content="Martin" />
    M.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Sellitto</span>,&#32;
    <meta itemprop="givenName" content="Michael" />
    M.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zhang</span>,&#32;
    <meta itemprop="givenName" content="Miranda" />
    M.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Kingsland</span>,&#32;
    <meta itemprop="givenName" content="Neerav" />
    N.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Elhage</span>,&#32;
    <meta itemprop="givenName" content="Nelson" />
    N.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Joseph</span>,&#32;
    <meta itemprop="givenName" content="Nicholas" />
    N.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Mercado</span>,&#32;
    <meta itemprop="givenName" content="Noemí" />
    N.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">DasSarma</span>,&#32;
    <meta itemprop="givenName" content="Nova" />
    N.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Rausch</span>,&#32;
    <meta itemprop="givenName" content="Oliver" />
    O.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Larson</span>,&#32;
    <meta itemprop="givenName" content="Robin" />
    R.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">McCandlish</span>,&#32;
    <meta itemprop="givenName" content="Sam" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Johnston</span>,&#32;
    <meta itemprop="givenName" content="Scott" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Kravec</span>,&#32;
    <meta itemprop="givenName" content="Shauna" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Showk</span>,&#32;
    <meta itemprop="givenName" content="Sheer El" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lanham</span>,&#32;
    <meta itemprop="givenName" content="Tamera" />
    T.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Telleen-Lawton</span>,&#32;
    <meta itemprop="givenName" content="Timothy" />
    T.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Brown</span>,&#32;
    <meta itemprop="givenName" content="Tom" />
    T.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Henighan</span>,&#32;
    <meta itemprop="givenName" content="Tom" />
    T.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Hume</span>,&#32;
    <meta itemprop="givenName" content="Tristan" />
    T.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Bai</span>,&#32;
    <meta itemprop="givenName" content="Yuntao" />
    Y.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Hatfield-Dodds</span>,&#32;
    <meta itemprop="givenName" content="Zac" />
    Z.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Clark</span>,&#32;
    <meta itemprop="givenName" content="Jack" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Bowman</span>,&#32;
    <meta itemprop="givenName" content="Samuel R." />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Askell</span>,&#32;
    <meta itemprop="givenName" content="Amanda" />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Grosse</span>,&#32;
    <meta itemprop="givenName" content="Roger" />
    R.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Hernandez</span>,&#32;
    <meta itemprop="givenName" content="Danny" />
    D.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Ganguli</span>,&#32;
    <meta itemprop="givenName" content="Deep" />
    D.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Hubinger</span>,&#32;
    <meta itemprop="givenName" content="Evan" />
    E.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Schiefer</span>,&#32;
    <meta itemprop="givenName" content="Nicholas" />
    N.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Kaplan</span>,&#32;
    <meta itemprop="givenName" content="Jared" />
    J.</span>
  &#32;
    (<span itemprop="datePublished">2022</span>).
  &#32;<span itemprop="name">Discovering Language Model Behaviors with Model-Written Evaluations</span>.
  <a href="https://doi.org/10.48550/arXiv.2212.09251"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.2212.09251</a></span>




</span></span>)</span> introduce evaluation data sets generated with the help of LMs. They create a variety of data sets, from simple &ldquo;yes/no&rdquo; and multiple choice questions to bias detecting schema similar to Winogender 
  <span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group"><a href="#rudinger2018genderbiascoreference"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Rachel"><span itemprop="familyName">Rudinger</span></span>&#32;
                &#32;et&#32;al.,&#32;<span itemprop="datePublished">2018</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Rudinger</span>,&#32;
    <meta itemprop="givenName" content="Rachel" />
    R.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Naradowsky</span>,&#32;
    <meta itemprop="givenName" content="Jason" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Leonard</span>,&#32;
    <meta itemprop="givenName" content="Brian" />
    B.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Van Durme</span>,&#32;
    <meta itemprop="givenName" content="Benjamin" />
    B.</span>
  &#32;
    (<span itemprop="datePublished">2018</span>).
  &#32;<span itemprop="name">Gender Bias in Coreference Resolution</span>.
  <a href="https://doi.org/10.48550/arXiv.1804.09301"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.1804.09301</a></span>




</span></span>)</span>. Compared to the conventional approach, they demonstrate a highly efficient data set generation process. Their approach may influence the generation of many future data sets.</p>
<h3 id="red-teaming">Red teaming<a hidden class="anchor" aria-hidden="true" href="#red-teaming">#</a></h3>
<p>
  <span class="hugo-cite-intext"
        itemprop="citation"><span class="hugo-cite-group"><a href="#ganguli2022redteaminglanguage"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Deep"><span itemprop="familyName">Ganguli</span></span>&#32;
                &#32;et&#32;al.&#32;(<span itemprop="datePublished">2022</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Ganguli</span>,&#32;
    <meta itemprop="givenName" content="Deep" />
    D.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lovitt</span>,&#32;
    <meta itemprop="givenName" content="Liane" />
    L.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Kernion</span>,&#32;
    <meta itemprop="givenName" content="Jackson" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Askell</span>,&#32;
    <meta itemprop="givenName" content="Amanda" />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Bai</span>,&#32;
    <meta itemprop="givenName" content="Yuntao" />
    Y.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Kadavath</span>,&#32;
    <meta itemprop="givenName" content="Saurav" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Mann</span>,&#32;
    <meta itemprop="givenName" content="Ben" />
    B.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Perez</span>,&#32;
    <meta itemprop="givenName" content="Ethan" />
    E.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Schiefer</span>,&#32;
    <meta itemprop="givenName" content="Nicholas" />
    N.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Ndousse</span>,&#32;
    <meta itemprop="givenName" content="Kamal" />
    K.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Jones</span>,&#32;
    <meta itemprop="givenName" content="Andy" />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Bowman</span>,&#32;
    <meta itemprop="givenName" content="Sam" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Chen</span>,&#32;
    <meta itemprop="givenName" content="Anna" />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Conerly</span>,&#32;
    <meta itemprop="givenName" content="Tom" />
    T.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">DasSarma</span>,&#32;
    <meta itemprop="givenName" content="Nova" />
    N.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Drain</span>,&#32;
    <meta itemprop="givenName" content="Dawn" />
    D.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Elhage</span>,&#32;
    <meta itemprop="givenName" content="Nelson" />
    N.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">El-Showk</span>,&#32;
    <meta itemprop="givenName" content="Sheer" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Fort</span>,&#32;
    <meta itemprop="givenName" content="Stanislav" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Hatfield-Dodds</span>,&#32;
    <meta itemprop="givenName" content="Zac" />
    Z.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Henighan</span>,&#32;
    <meta itemprop="givenName" content="Tom" />
    T.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Hernandez</span>,&#32;
    <meta itemprop="givenName" content="Danny" />
    D.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Hume</span>,&#32;
    <meta itemprop="givenName" content="Tristan" />
    T.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Jacobson</span>,&#32;
    <meta itemprop="givenName" content="Josh" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Johnston</span>,&#32;
    <meta itemprop="givenName" content="Scott" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Kravec</span>,&#32;
    <meta itemprop="givenName" content="Shauna" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Olsson</span>,&#32;
    <meta itemprop="givenName" content="Catherine" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Ringer</span>,&#32;
    <meta itemprop="givenName" content="Sam" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Tran-Johnson</span>,&#32;
    <meta itemprop="givenName" content="Eli" />
    E.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Amodei</span>,&#32;
    <meta itemprop="givenName" content="Dario" />
    D.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Brown</span>,&#32;
    <meta itemprop="givenName" content="Tom" />
    T.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Joseph</span>,&#32;
    <meta itemprop="givenName" content="Nicholas" />
    N.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">McCandlish</span>,&#32;
    <meta itemprop="givenName" content="Sam" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Olah</span>,&#32;
    <meta itemprop="givenName" content="Chris" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Kaplan</span>,&#32;
    <meta itemprop="givenName" content="Jared" />
    J.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Clark</span>,&#32;
    <meta itemprop="givenName" content="Jack" />
    J.</span>
  &#32;
    (<span itemprop="datePublished">2022</span>).
  &#32;<span itemprop="name">Red Teaming Language Models to Reduce Harms: Methods, Scaling Behaviors, and Lessons Learned</span>.
  <a href="https://doi.org/10.48550/arXiv.2209.07858"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.2209.07858</a></span>




</span></span>)</span> share their experience manually red-teaming LMs. They define LM read teaming as &ldquo;using manual or automated methods to adversarially probe a language model for harmful outputs, and then updating the model to avoid such outputs&rdquo;. 
  <span class="hugo-cite-intext"
        itemprop="citation"><span class="hugo-cite-group"><a href="#perez2022redteaminglanguage"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Ethan"><span itemprop="familyName">Perez</span></span>&#32;
                &#32;et&#32;al.&#32;(<span itemprop="datePublished">2022</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Perez</span>,&#32;
    <meta itemprop="givenName" content="Ethan" />
    E.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Huang</span>,&#32;
    <meta itemprop="givenName" content="Saffron" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Song</span>,&#32;
    <meta itemprop="givenName" content="Francis" />
    F.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Cai</span>,&#32;
    <meta itemprop="givenName" content="Trevor" />
    T.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Ring</span>,&#32;
    <meta itemprop="givenName" content="Roman" />
    R.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Aslanides</span>,&#32;
    <meta itemprop="givenName" content="John" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Glaese</span>,&#32;
    <meta itemprop="givenName" content="Amelia" />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">McAleese</span>,&#32;
    <meta itemprop="givenName" content="Nat" />
    N.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Irving</span>,&#32;
    <meta itemprop="givenName" content="Geoffrey" />
    G.</span>
  &#32;
    (<span itemprop="datePublished">2022</span>).
  &#32;<span itemprop="name">Red Teaming Language Models with Language Models</span>.
  <a href="https://doi.org/10.48550/arXiv.2202.03286"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.2202.03286</a></span>




</span></span>)</span> introduce an automated version of red teaming, where the red team itself is a language model.</p>
<h2 id="4-conclusion">4. Conclusion<a hidden class="anchor" aria-hidden="true" href="#4-conclusion">#</a></h2>
<p>In this post, I gave an overview of some of the NLP benchmarks used for evaluating modern language models (LMs), such as InstructGPT. Despite best efforts and in many ways impressive performance, the output of current state-of-the-art LMs often fails to satisfy many desirable characterics, such as truthfulness. Reliably quantifying these issues presents on important step towards building better LMs and developing downstream applications. Adaptive benchmarks, such as HellaSwag with adverserial filtering 
  <span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group"><a href="#zellers2019hellaswagcanmachine"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Rowan"><span itemprop="familyName">Zellers</span></span>&#32;
                &#32;et&#32;al.,&#32;<span itemprop="datePublished">2019</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zellers</span>,&#32;
    <meta itemprop="givenName" content="Rowan" />
    R.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Holtzman</span>,&#32;
    <meta itemprop="givenName" content="Ari" />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Bisk</span>,&#32;
    <meta itemprop="givenName" content="Yonatan" />
    Y.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Farhadi</span>,&#32;
    <meta itemprop="givenName" content="Ali" />
    A.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Choi</span>,&#32;
    <meta itemprop="givenName" content="Yejin" />
    Y.</span>
  &#32;
    (<span itemprop="datePublished">2019</span>).
  &#32;<span itemprop="name">HellaSwag: Can a Machine Really Finish Your Sentence?</span>.
  <a href="https://doi.org/10.48550/arXiv.1905.07830"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.1905.07830</a></span>




</span></span>)</span>, present one promising direction to creating benchmarks that co-evolve as models grow more and more powerful.</p>
<h2 id="acknowledgements">Acknowledgements<a hidden class="anchor" aria-hidden="true" href="#acknowledgements">#</a></h2>
<p>I would like to thank <a href="https://simonmathis.com/">Simon Mathis</a> for pointing me to the excellent paper by 
  <span class="hugo-cite-intext"
        itemprop="citation"><span class="hugo-cite-group"><a href="#niven2019probingneuralnetwork"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Timothy"><span itemprop="familyName">Niven</span></span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Hung-Yu"><span itemprop="familyName">Kao</span></span>&#32;(<span itemprop="datePublished">2019</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/CreativeWork"
      data-type="paper-conference"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Niven</span>,&#32;
    <meta itemprop="givenName" content="Timothy" />
    T.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Kao</span>,&#32;
    <meta itemprop="givenName" content="Hung-Yu" />
    H.</span>
  &#32;
    (<span itemprop="datePublished">2019</span>).
  &#32;<span itemprop="name">
    <i>Probing Neural Network Comprehension of Natural Language Arguments</i></span>.
  <meta itemprop="contentLocation"
        content="Florence, Italy">&#32;
  <span itemprop="publisher" itemtype="http://schema.org/Organization" itemscope="">
    <span itemprop="name">Association for Computational Linguistics</span></span>.
  <a href="https://doi.org/10.18653/v1/P19-1459"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.18653/v1/P19-1459</a></span>

</span></span>)</span>.</p>
<h2 id="references">References<a hidden class="anchor" aria-hidden="true" href="#references">#</a></h2>

  

  










<section class="hugo-cite-bibliography">
  <ol>
    

      <div id="bojar2015findings2015workshop">
        

        <li>
          










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Bojar</span>,&#32;
    <meta itemprop="givenName" content="Ondrej" />
    O.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Chatterjee</span>,&#32;
    <meta itemprop="givenName" content="Rajen" />
    R.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Federmann</span>,&#32;
    <meta itemprop="givenName" content="Christian" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Haddow</span>,&#32;
    <meta itemprop="givenName" content="Barry" />
    B.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Huck</span>,&#32;
    <meta itemprop="givenName" content="Matthias" />
    M.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Hokamp</span>,&#32;
    <meta itemprop="givenName" content="Chris" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Koehn</span>,&#32;
    <meta itemprop="givenName" content="Philipp" />
    P.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Logacheva</span>,&#32;
    <meta itemprop="givenName" content="Varvara" />
    V.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Monz</span>,&#32;
    <meta itemprop="givenName" content="Christof" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Negri</span>,&#32;
    <meta itemprop="givenName" content="Matteo" />
    M.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Post</span>,&#32;
    <meta itemprop="givenName" content="Matt" />
    M.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Scarton</span>,&#32;
    <meta itemprop="givenName" content="Carolina" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Specia</span>,&#32;
    <meta itemprop="givenName" content="Lucia" />
    L.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Turchi</span>,&#32;
    <meta itemprop="givenName" content="Marco" />
    M.</span>
  &#32;
    (<span itemprop="datePublished">2015</span>).
  &#32;<span itemprop="name">Findings of the 2015 Workshop on Statistical Machine Translation</span>.<i>
    <span itemprop="about">Proceedings of the Tenth Workshop on Statistical Machine Translation</span></i>.&#32;<span itemprop="pagination">1–46</span>.&#32;Retrieved from&#32;
  <a href="https://www.research.ed.ac.uk/en/publications/findings-of-the-2015-workshop-on-statistical-machine-translation"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://www.research.ed.ac.uk/en/publications/findings-of-the-2015-workshop-on-statistical-machine-translation</a></span>




</li>

      </div>

      <div id="dua2019dropreadingcomprehension">
        

        <li>
          










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Dua</span>,&#32;
    <meta itemprop="givenName" content="Dheeru" />
    D.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Wang</span>,&#32;
    <meta itemprop="givenName" content="Yizhong" />
    Y.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Dasigi</span>,&#32;
    <meta itemprop="givenName" content="Pradeep" />
    P.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Stanovsky</span>,&#32;
    <meta itemprop="givenName" content="Gabriel" />
    G.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Singh</span>,&#32;
    <meta itemprop="givenName" content="Sameer" />
    S.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Gardner</span>,&#32;
    <meta itemprop="givenName" content="Matt" />
    M.</span>
  &#32;
    (<span itemprop="datePublished">2019</span>).
  &#32;<span itemprop="name">DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs</span>.
  <a href="https://doi.org/10.48550/arXiv.1903.00161"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.1903.00161</a></span>




</li>

      </div>

      <div id="ganguli2022redteaminglanguage">
        

        <li>
          










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Ganguli</span>,&#32;
    <meta itemprop="givenName" content="Deep" />
    D.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lovitt</span>,&#32;
    <meta itemprop="givenName" content="Liane" />
    L.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Kernion</span>,&#32;
    <meta itemprop="givenName" content="Jackson" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Askell</span>,&#32;
    <meta itemprop="givenName" content="Amanda" />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Bai</span>,&#32;
    <meta itemprop="givenName" content="Yuntao" />
    Y.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Kadavath</span>,&#32;
    <meta itemprop="givenName" content="Saurav" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Mann</span>,&#32;
    <meta itemprop="givenName" content="Ben" />
    B.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Perez</span>,&#32;
    <meta itemprop="givenName" content="Ethan" />
    E.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Schiefer</span>,&#32;
    <meta itemprop="givenName" content="Nicholas" />
    N.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Ndousse</span>,&#32;
    <meta itemprop="givenName" content="Kamal" />
    K.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Jones</span>,&#32;
    <meta itemprop="givenName" content="Andy" />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Bowman</span>,&#32;
    <meta itemprop="givenName" content="Sam" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Chen</span>,&#32;
    <meta itemprop="givenName" content="Anna" />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Conerly</span>,&#32;
    <meta itemprop="givenName" content="Tom" />
    T.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">DasSarma</span>,&#32;
    <meta itemprop="givenName" content="Nova" />
    N.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Drain</span>,&#32;
    <meta itemprop="givenName" content="Dawn" />
    D.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Elhage</span>,&#32;
    <meta itemprop="givenName" content="Nelson" />
    N.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">El-Showk</span>,&#32;
    <meta itemprop="givenName" content="Sheer" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Fort</span>,&#32;
    <meta itemprop="givenName" content="Stanislav" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Hatfield-Dodds</span>,&#32;
    <meta itemprop="givenName" content="Zac" />
    Z.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Henighan</span>,&#32;
    <meta itemprop="givenName" content="Tom" />
    T.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Hernandez</span>,&#32;
    <meta itemprop="givenName" content="Danny" />
    D.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Hume</span>,&#32;
    <meta itemprop="givenName" content="Tristan" />
    T.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Jacobson</span>,&#32;
    <meta itemprop="givenName" content="Josh" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Johnston</span>,&#32;
    <meta itemprop="givenName" content="Scott" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Kravec</span>,&#32;
    <meta itemprop="givenName" content="Shauna" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Olsson</span>,&#32;
    <meta itemprop="givenName" content="Catherine" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Ringer</span>,&#32;
    <meta itemprop="givenName" content="Sam" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Tran-Johnson</span>,&#32;
    <meta itemprop="givenName" content="Eli" />
    E.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Amodei</span>,&#32;
    <meta itemprop="givenName" content="Dario" />
    D.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Brown</span>,&#32;
    <meta itemprop="givenName" content="Tom" />
    T.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Joseph</span>,&#32;
    <meta itemprop="givenName" content="Nicholas" />
    N.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">McCandlish</span>,&#32;
    <meta itemprop="givenName" content="Sam" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Olah</span>,&#32;
    <meta itemprop="givenName" content="Chris" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Kaplan</span>,&#32;
    <meta itemprop="givenName" content="Jared" />
    J.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Clark</span>,&#32;
    <meta itemprop="givenName" content="Jack" />
    J.</span>
  &#32;
    (<span itemprop="datePublished">2022</span>).
  &#32;<span itemprop="name">Red Teaming Language Models to Reduce Harms: Methods, Scaling Behaviors, and Lessons Learned</span>.
  <a href="https://doi.org/10.48550/arXiv.2209.07858"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.2209.07858</a></span>




</li>

      </div>

      <div id="gehman2020realtoxicitypromptsevaluatingneural">
        

        <li>
          










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Gehman</span>,&#32;
    <meta itemprop="givenName" content="Samuel" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Gururangan</span>,&#32;
    <meta itemprop="givenName" content="Suchin" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Sap</span>,&#32;
    <meta itemprop="givenName" content="Maarten" />
    M.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Choi</span>,&#32;
    <meta itemprop="givenName" content="Yejin" />
    Y.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Smith</span>,&#32;
    <meta itemprop="givenName" content="Noah A." />
    N.</span>
  &#32;
    (<span itemprop="datePublished">2020</span>).
  &#32;<span itemprop="name">RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models</span>.
  <a href="https://doi.org/10.48550/arXiv.2009.11462"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.2009.11462</a></span>




</li>

      </div>

      <div id="lin2022truthfulqameasuringhow">
        

        <li>
          










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lin</span>,&#32;
    <meta itemprop="givenName" content="Stephanie" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Hilton</span>,&#32;
    <meta itemprop="givenName" content="Jacob" />
    J.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Evans</span>,&#32;
    <meta itemprop="givenName" content="Owain" />
    O.</span>
  &#32;
    (<span itemprop="datePublished">2022</span>).
  &#32;<span itemprop="name">TruthfulQA: Measuring How Models Mimic Human Falsehoods</span>.
  <a href="https://doi.org/10.48550/arXiv.2109.07958"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.2109.07958</a></span>




</li>

      </div>

      <div id="nallapati2016abstractivetextsummarization">
        

        <li>
          










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Nallapati</span>,&#32;
    <meta itemprop="givenName" content="Ramesh" />
    R.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zhou</span>,&#32;
    <meta itemprop="givenName" content="Bowen" />
    B.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">santos</span>,&#32;
    <meta itemprop="givenName" content="Cicero Nogueira" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Gulcehre</span>,&#32;
    <meta itemprop="givenName" content="Caglar" />
    C.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Xiang</span>,&#32;
    <meta itemprop="givenName" content="Bing" />
    B.</span>
  &#32;
    (<span itemprop="datePublished">2016</span>).
  &#32;<span itemprop="name">Abstractive Text Summarization Using Sequence-to-Sequence RNNs and Beyond</span>.
  <a href="https://doi.org/10.48550/arXiv.1602.06023"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.1602.06023</a></span>




</li>

      </div>

      <div id="nangia2020crowspairschallengedataset">
        

        <li>
          










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Nangia</span>,&#32;
    <meta itemprop="givenName" content="Nikita" />
    N.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Vania</span>,&#32;
    <meta itemprop="givenName" content="Clara" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Bhalerao</span>,&#32;
    <meta itemprop="givenName" content="Rasika" />
    R.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Bowman</span>,&#32;
    <meta itemprop="givenName" content="Samuel R." />
    S.</span>
  &#32;
    (<span itemprop="datePublished">2020</span>).
  &#32;<span itemprop="name">CrowS-Pairs: A Challenge Dataset for Measuring Social Biases in Masked Language Models</span>.
  <a href="https://doi.org/10.48550/arXiv.2010.00133"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.2010.00133</a></span>




</li>

      </div>

      <div id="niven2019probingneuralnetwork">
        

        <li>
          










<span itemscope
      itemtype="https://schema.org/CreativeWork"
      data-type="paper-conference"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Niven</span>,&#32;
    <meta itemprop="givenName" content="Timothy" />
    T.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Kao</span>,&#32;
    <meta itemprop="givenName" content="Hung-Yu" />
    H.</span>
  &#32;
    (<span itemprop="datePublished">2019</span>).
  &#32;<span itemprop="name">
    <i>Probing Neural Network Comprehension of Natural Language Arguments</i></span>.
  <meta itemprop="contentLocation"
        content="Florence, Italy">&#32;
  <span itemprop="publisher" itemtype="http://schema.org/Organization" itemscope="">
    <span itemprop="name">Association for Computational Linguistics</span></span>.
  <a href="https://doi.org/10.18653/v1/P19-1459"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.18653/v1/P19-1459</a></span>

</li>

      </div>

      <div id="ouyang2022traininglanguagemodels">
        

        <li>
          










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Ouyang</span>,&#32;
    <meta itemprop="givenName" content="Long" />
    L.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Wu</span>,&#32;
    <meta itemprop="givenName" content="Jeff" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Jiang</span>,&#32;
    <meta itemprop="givenName" content="Xu" />
    X.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Almeida</span>,&#32;
    <meta itemprop="givenName" content="Diogo" />
    D.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Wainwright</span>,&#32;
    <meta itemprop="givenName" content="Carroll L." />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Mishkin</span>,&#32;
    <meta itemprop="givenName" content="Pamela" />
    P.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zhang</span>,&#32;
    <meta itemprop="givenName" content="Chong" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Agarwal</span>,&#32;
    <meta itemprop="givenName" content="Sandhini" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Slama</span>,&#32;
    <meta itemprop="givenName" content="Katarina" />
    K.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Ray</span>,&#32;
    <meta itemprop="givenName" content="Alex" />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Schulman</span>,&#32;
    <meta itemprop="givenName" content="John" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Hilton</span>,&#32;
    <meta itemprop="givenName" content="Jacob" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Kelton</span>,&#32;
    <meta itemprop="givenName" content="Fraser" />
    F.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Miller</span>,&#32;
    <meta itemprop="givenName" content="Luke" />
    L.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Simens</span>,&#32;
    <meta itemprop="givenName" content="Maddie" />
    M.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Askell</span>,&#32;
    <meta itemprop="givenName" content="Amanda" />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Welinder</span>,&#32;
    <meta itemprop="givenName" content="Peter" />
    P.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Christiano</span>,&#32;
    <meta itemprop="givenName" content="Paul" />
    P.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Leike</span>,&#32;
    <meta itemprop="givenName" content="Jan" />
    J.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lowe</span>,&#32;
    <meta itemprop="givenName" content="Ryan" />
    R.</span>
  &#32;
    (<span itemprop="datePublished">2022</span>).
  &#32;<span itemprop="name">Training language models to follow instructions with human feedback</span>.&#32;Retrieved from&#32;
  <a href="http://arxiv.org/abs/2203.02155"
     itemprop="identifier"
     itemtype="https://schema.org/URL">http://arxiv.org/abs/2203.02155</a></span>




</li>

      </div>

      <div id="papineni2002bleumethodautomatic">
        

        <li>
          










<span itemscope
      itemtype="https://schema.org/CreativeWork"
      data-type="paper-conference"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Papineni</span>,&#32;
    <meta itemprop="givenName" content="Kishore" />
    K.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Roukos</span>,&#32;
    <meta itemprop="givenName" content="Salim" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Ward</span>,&#32;
    <meta itemprop="givenName" content="Todd" />
    T.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zhu</span>,&#32;
    <meta itemprop="givenName" content="Wei-Jing" />
    W.</span>
  &#32;
    (<span itemprop="datePublished">2002</span>).
  &#32;<span itemprop="name">
    <i>BLEU: a method for automatic evaluation of machine translation</i></span>.
  </span>

</li>

      </div>

      <div id="perez2022discoveringlanguagemodel">
        

        <li>
          










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Perez</span>,&#32;
    <meta itemprop="givenName" content="Ethan" />
    E.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"></span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lukošiūtė</span>,&#32;
    <meta itemprop="givenName" content="Kamilė" />
    K.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Nguyen</span>,&#32;
    <meta itemprop="givenName" content="Karina" />
    K.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Chen</span>,&#32;
    <meta itemprop="givenName" content="Edwin" />
    E.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Heiner</span>,&#32;
    <meta itemprop="givenName" content="Scott" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Pettit</span>,&#32;
    <meta itemprop="givenName" content="Craig" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Olsson</span>,&#32;
    <meta itemprop="givenName" content="Catherine" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Kundu</span>,&#32;
    <meta itemprop="givenName" content="Sandipan" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Kadavath</span>,&#32;
    <meta itemprop="givenName" content="Saurav" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Jones</span>,&#32;
    <meta itemprop="givenName" content="Andy" />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Chen</span>,&#32;
    <meta itemprop="givenName" content="Anna" />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Mann</span>,&#32;
    <meta itemprop="givenName" content="Ben" />
    B.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Israel</span>,&#32;
    <meta itemprop="givenName" content="Brian" />
    B.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Seethor</span>,&#32;
    <meta itemprop="givenName" content="Bryan" />
    B.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">McKinnon</span>,&#32;
    <meta itemprop="givenName" content="Cameron" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Olah</span>,&#32;
    <meta itemprop="givenName" content="Christopher" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Yan</span>,&#32;
    <meta itemprop="givenName" content="Da" />
    D.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Amodei</span>,&#32;
    <meta itemprop="givenName" content="Daniela" />
    D.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Amodei</span>,&#32;
    <meta itemprop="givenName" content="Dario" />
    D.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Drain</span>,&#32;
    <meta itemprop="givenName" content="Dawn" />
    D.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Li</span>,&#32;
    <meta itemprop="givenName" content="Dustin" />
    D.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Tran-Johnson</span>,&#32;
    <meta itemprop="givenName" content="Eli" />
    E.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Khundadze</span>,&#32;
    <meta itemprop="givenName" content="Guro" />
    G.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Kernion</span>,&#32;
    <meta itemprop="givenName" content="Jackson" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Landis</span>,&#32;
    <meta itemprop="givenName" content="James" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Kerr</span>,&#32;
    <meta itemprop="givenName" content="Jamie" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Mueller</span>,&#32;
    <meta itemprop="givenName" content="Jared" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Hyun</span>,&#32;
    <meta itemprop="givenName" content="Jeeyoon" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Landau</span>,&#32;
    <meta itemprop="givenName" content="Joshua" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Ndousse</span>,&#32;
    <meta itemprop="givenName" content="Kamal" />
    K.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Goldberg</span>,&#32;
    <meta itemprop="givenName" content="Landon" />
    L.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lovitt</span>,&#32;
    <meta itemprop="givenName" content="Liane" />
    L.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lucas</span>,&#32;
    <meta itemprop="givenName" content="Martin" />
    M.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Sellitto</span>,&#32;
    <meta itemprop="givenName" content="Michael" />
    M.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zhang</span>,&#32;
    <meta itemprop="givenName" content="Miranda" />
    M.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Kingsland</span>,&#32;
    <meta itemprop="givenName" content="Neerav" />
    N.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Elhage</span>,&#32;
    <meta itemprop="givenName" content="Nelson" />
    N.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Joseph</span>,&#32;
    <meta itemprop="givenName" content="Nicholas" />
    N.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Mercado</span>,&#32;
    <meta itemprop="givenName" content="Noemí" />
    N.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">DasSarma</span>,&#32;
    <meta itemprop="givenName" content="Nova" />
    N.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Rausch</span>,&#32;
    <meta itemprop="givenName" content="Oliver" />
    O.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Larson</span>,&#32;
    <meta itemprop="givenName" content="Robin" />
    R.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">McCandlish</span>,&#32;
    <meta itemprop="givenName" content="Sam" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Johnston</span>,&#32;
    <meta itemprop="givenName" content="Scott" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Kravec</span>,&#32;
    <meta itemprop="givenName" content="Shauna" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Showk</span>,&#32;
    <meta itemprop="givenName" content="Sheer El" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lanham</span>,&#32;
    <meta itemprop="givenName" content="Tamera" />
    T.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Telleen-Lawton</span>,&#32;
    <meta itemprop="givenName" content="Timothy" />
    T.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Brown</span>,&#32;
    <meta itemprop="givenName" content="Tom" />
    T.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Henighan</span>,&#32;
    <meta itemprop="givenName" content="Tom" />
    T.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Hume</span>,&#32;
    <meta itemprop="givenName" content="Tristan" />
    T.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Bai</span>,&#32;
    <meta itemprop="givenName" content="Yuntao" />
    Y.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Hatfield-Dodds</span>,&#32;
    <meta itemprop="givenName" content="Zac" />
    Z.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Clark</span>,&#32;
    <meta itemprop="givenName" content="Jack" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Bowman</span>,&#32;
    <meta itemprop="givenName" content="Samuel R." />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Askell</span>,&#32;
    <meta itemprop="givenName" content="Amanda" />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Grosse</span>,&#32;
    <meta itemprop="givenName" content="Roger" />
    R.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Hernandez</span>,&#32;
    <meta itemprop="givenName" content="Danny" />
    D.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Ganguli</span>,&#32;
    <meta itemprop="givenName" content="Deep" />
    D.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Hubinger</span>,&#32;
    <meta itemprop="givenName" content="Evan" />
    E.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Schiefer</span>,&#32;
    <meta itemprop="givenName" content="Nicholas" />
    N.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Kaplan</span>,&#32;
    <meta itemprop="givenName" content="Jared" />
    J.</span>
  &#32;
    (<span itemprop="datePublished">2022</span>).
  &#32;<span itemprop="name">Discovering Language Model Behaviors with Model-Written Evaluations</span>.
  <a href="https://doi.org/10.48550/arXiv.2212.09251"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.2212.09251</a></span>




</li>

      </div>

      <div id="perez2022redteaminglanguage">
        

        <li>
          










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Perez</span>,&#32;
    <meta itemprop="givenName" content="Ethan" />
    E.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Huang</span>,&#32;
    <meta itemprop="givenName" content="Saffron" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Song</span>,&#32;
    <meta itemprop="givenName" content="Francis" />
    F.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Cai</span>,&#32;
    <meta itemprop="givenName" content="Trevor" />
    T.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Ring</span>,&#32;
    <meta itemprop="givenName" content="Roman" />
    R.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Aslanides</span>,&#32;
    <meta itemprop="givenName" content="John" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Glaese</span>,&#32;
    <meta itemprop="givenName" content="Amelia" />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">McAleese</span>,&#32;
    <meta itemprop="givenName" content="Nat" />
    N.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Irving</span>,&#32;
    <meta itemprop="givenName" content="Geoffrey" />
    G.</span>
  &#32;
    (<span itemprop="datePublished">2022</span>).
  &#32;<span itemprop="name">Red Teaming Language Models with Language Models</span>.
  <a href="https://doi.org/10.48550/arXiv.2202.03286"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.2202.03286</a></span>




</li>

      </div>

      <div id="rajpurkar2016squad100000">
        

        <li>
          










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Rajpurkar</span>,&#32;
    <meta itemprop="givenName" content="Pranav" />
    P.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zhang</span>,&#32;
    <meta itemprop="givenName" content="Jian" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lopyrev</span>,&#32;
    <meta itemprop="givenName" content="Konstantin" />
    K.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Liang</span>,&#32;
    <meta itemprop="givenName" content="Percy" />
    P.</span>
  &#32;
    (<span itemprop="datePublished">2016</span>).
  &#32;<span itemprop="name">SQuAD: 100,000+ Questions for Machine Comprehension of Text</span>.
  <a href="https://doi.org/10.48550/arXiv.1606.05250"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.1606.05250</a></span>




</li>

      </div>

      <div id="rajpurkar2018knowwhatyou">
        

        <li>
          










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Rajpurkar</span>,&#32;
    <meta itemprop="givenName" content="Pranav" />
    P.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Jia</span>,&#32;
    <meta itemprop="givenName" content="Robin" />
    R.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Liang</span>,&#32;
    <meta itemprop="givenName" content="Percy" />
    P.</span>
  &#32;
    (<span itemprop="datePublished">2018</span>).
  &#32;<span itemprop="name">Know What You Don&rsquo;t Know: Unanswerable Questions for SQuAD</span>.
  <a href="https://doi.org/10.48550/arXiv.1806.03822"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.1806.03822</a></span>




</li>

      </div>

      <div id="rudinger2018genderbiascoreference">
        

        <li>
          










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Rudinger</span>,&#32;
    <meta itemprop="givenName" content="Rachel" />
    R.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Naradowsky</span>,&#32;
    <meta itemprop="givenName" content="Jason" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Leonard</span>,&#32;
    <meta itemprop="givenName" content="Brian" />
    B.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Van Durme</span>,&#32;
    <meta itemprop="givenName" content="Benjamin" />
    B.</span>
  &#32;
    (<span itemprop="datePublished">2018</span>).
  &#32;<span itemprop="name">Gender Bias in Coreference Resolution</span>.
  <a href="https://doi.org/10.48550/arXiv.1804.09301"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.1804.09301</a></span>




</li>

      </div>

      <div id="socher2013recursivedeepmodels">
        

        <li>
          










<span itemscope
      itemtype="https://schema.org/CreativeWork"
      data-type="paper-conference"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Socher</span>,&#32;
    <meta itemprop="givenName" content="Richard" />
    R.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Perelygin</span>,&#32;
    <meta itemprop="givenName" content="Alex" />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Wu</span>,&#32;
    <meta itemprop="givenName" content="Jean" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Chuang</span>,&#32;
    <meta itemprop="givenName" content="Jason" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Manning</span>,&#32;
    <meta itemprop="givenName" content="Christopher D." />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Ng</span>,&#32;
    <meta itemprop="givenName" content="Andrew Y." />
    A.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Potts</span>,&#32;
    <meta itemprop="givenName" content="Christopher" />
    C.</span>
  &#32;
    (<span itemprop="datePublished">2013</span>).
  &#32;<span itemprop="name">
    <i>Recursive deep models for semantic compositionality over a sentiment treebank</i></span>.
  </span>

</li>

      </div>

      <div id="volske2017tldrmining">
        

        <li>
          










<span itemscope
      itemtype="https://schema.org/CreativeWork"
      data-type="paper-conference"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Völske</span>,&#32;
    <meta itemprop="givenName" content="Michael" />
    M.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Potthast</span>,&#32;
    <meta itemprop="givenName" content="Martin" />
    M.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Syed</span>,&#32;
    <meta itemprop="givenName" content="Shahbaz" />
    S.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Stein</span>,&#32;
    <meta itemprop="givenName" content="Benno" />
    B.</span>
  &#32;
    (<span itemprop="datePublished">2017</span>).
  &#32;<span itemprop="name">
    <i>Tl; dr: Mining reddit to learn automatic summarization</i></span>.
  </span>

</li>

      </div>

      <div id="wang2019supergluestickierbenchmark">
        

        <li>
          










<span itemscope
      itemtype="https://schema.org/CreativeWork"
      data-type="paper-conference"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Wang</span>,&#32;
    <meta itemprop="givenName" content="Alex" />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Pruksachatkun</span>,&#32;
    <meta itemprop="givenName" content="Yada" />
    Y.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Nangia</span>,&#32;
    <meta itemprop="givenName" content="Nikita" />
    N.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Singh</span>,&#32;
    <meta itemprop="givenName" content="Amanpreet" />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Michael</span>,&#32;
    <meta itemprop="givenName" content="Julian" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Hill</span>,&#32;
    <meta itemprop="givenName" content="Felix" />
    F.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Levy</span>,&#32;
    <meta itemprop="givenName" content="Omer" />
    O.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Bowman</span>,&#32;
    <meta itemprop="givenName" content="Samuel" />
    S.</span>
  &#32;
    (<span itemprop="datePublished">2019</span>).
  &#32;<span itemprop="name">
    <i>SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems</i></span>.
  &#32;
  <span itemprop="publisher" itemtype="http://schema.org/Organization" itemscope="">
    <span itemprop="name">Curran Associates, Inc.</span></span>.&#32;Retrieved from&#32;
  <a href="https://proceedings.neurips.cc/paper/2019/hash/4496bf24afe7fab6f046bf4923da8de6-Abstract.html"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://proceedings.neurips.cc/paper/2019/hash/4496bf24afe7fab6f046bf4923da8de6-Abstract.html</a></span>

</li>

      </div>

      <div id="zellers2018swaglargescaleadversarial">
        

        <li>
          










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zellers</span>,&#32;
    <meta itemprop="givenName" content="Rowan" />
    R.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Bisk</span>,&#32;
    <meta itemprop="givenName" content="Yonatan" />
    Y.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Schwartz</span>,&#32;
    <meta itemprop="givenName" content="Roy" />
    R.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Choi</span>,&#32;
    <meta itemprop="givenName" content="Yejin" />
    Y.</span>
  &#32;
    (<span itemprop="datePublished">2018</span>).
  &#32;<span itemprop="name">SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference</span>.
  <a href="https://doi.org/10.48550/arXiv.1808.05326"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.1808.05326</a></span>




</li>

      </div>

      <div id="zellers2019hellaswagcanmachine">
        

        <li>
          










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zellers</span>,&#32;
    <meta itemprop="givenName" content="Rowan" />
    R.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Holtzman</span>,&#32;
    <meta itemprop="givenName" content="Ari" />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Bisk</span>,&#32;
    <meta itemprop="givenName" content="Yonatan" />
    Y.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Farhadi</span>,&#32;
    <meta itemprop="givenName" content="Ali" />
    A.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Choi</span>,&#32;
    <meta itemprop="givenName" content="Yejin" />
    Y.</span>
  &#32;
    (<span itemprop="datePublished">2019</span>).
  &#32;<span itemprop="name">HellaSwag: Can a Machine Really Finish Your Sentence?</span>.
  <a href="https://doi.org/10.48550/arXiv.1905.07830"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.1905.07830</a></span>




</li>

      </div>
  </ol>
</section>



<h2 id="appendix">Appendix<a hidden class="anchor" aria-hidden="true" href="#appendix">#</a></h2>
<h3 id="a-instructgpt-automatic-evaluation-results">A. InstructGPT automatic evaluation results<a hidden class="anchor" aria-hidden="true" href="#a-instructgpt-automatic-evaluation-results">#</a></h3>
<p>Whilst the ChatGPT results on these benchmarks are unkown, we can look at the results of InstructGPT to get glimpse of the likely capabilities of ChatGPT. The figure below is taken from the InstructGPT paper 
  <span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group"><a href="#ouyang2022traininglanguagemodels"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Long"><span itemprop="familyName">Ouyang</span></span>&#32;
                &#32;et&#32;al.,&#32;<span itemprop="datePublished">2022</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Ouyang</span>,&#32;
    <meta itemprop="givenName" content="Long" />
    L.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Wu</span>,&#32;
    <meta itemprop="givenName" content="Jeff" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Jiang</span>,&#32;
    <meta itemprop="givenName" content="Xu" />
    X.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Almeida</span>,&#32;
    <meta itemprop="givenName" content="Diogo" />
    D.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Wainwright</span>,&#32;
    <meta itemprop="givenName" content="Carroll L." />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Mishkin</span>,&#32;
    <meta itemprop="givenName" content="Pamela" />
    P.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zhang</span>,&#32;
    <meta itemprop="givenName" content="Chong" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Agarwal</span>,&#32;
    <meta itemprop="givenName" content="Sandhini" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Slama</span>,&#32;
    <meta itemprop="givenName" content="Katarina" />
    K.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Ray</span>,&#32;
    <meta itemprop="givenName" content="Alex" />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Schulman</span>,&#32;
    <meta itemprop="givenName" content="John" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Hilton</span>,&#32;
    <meta itemprop="givenName" content="Jacob" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Kelton</span>,&#32;
    <meta itemprop="givenName" content="Fraser" />
    F.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Miller</span>,&#32;
    <meta itemprop="givenName" content="Luke" />
    L.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Simens</span>,&#32;
    <meta itemprop="givenName" content="Maddie" />
    M.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Askell</span>,&#32;
    <meta itemprop="givenName" content="Amanda" />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Welinder</span>,&#32;
    <meta itemprop="givenName" content="Peter" />
    P.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Christiano</span>,&#32;
    <meta itemprop="givenName" content="Paul" />
    P.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Leike</span>,&#32;
    <meta itemprop="givenName" content="Jan" />
    J.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lowe</span>,&#32;
    <meta itemprop="givenName" content="Ryan" />
    R.</span>
  &#32;
    (<span itemprop="datePublished">2022</span>).
  &#32;<span itemprop="name">Training language models to follow instructions with human feedback</span>.&#32;Retrieved from&#32;
  <a href="http://arxiv.org/abs/2203.02155"
     itemprop="identifier"
     itemtype="https://schema.org/URL">http://arxiv.org/abs/2203.02155</a></span>




</span></span>)</span>.</p>
<center>


<figure style="text-align: center;"><img class="screenshot"
         src="results_instruct_gpt.png" width="100%"style="display:inline"
    /><figcaption>
        <p align="center">Results of InstructGPT on public NLP benchmarks. Figure from 
  <span class="hugo-cite-intext"
        itemprop="citation"><span class="hugo-cite-group"><a href="#ouyang2022traininglanguagemodels"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Long"><span itemprop="familyName">Ouyang</span></span>&#32;
                &#32;et&#32;al.&#32;(<span itemprop="datePublished">2022</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Ouyang</span>,&#32;
    <meta itemprop="givenName" content="Long" />
    L.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Wu</span>,&#32;
    <meta itemprop="givenName" content="Jeff" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Jiang</span>,&#32;
    <meta itemprop="givenName" content="Xu" />
    X.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Almeida</span>,&#32;
    <meta itemprop="givenName" content="Diogo" />
    D.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Wainwright</span>,&#32;
    <meta itemprop="givenName" content="Carroll L." />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Mishkin</span>,&#32;
    <meta itemprop="givenName" content="Pamela" />
    P.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zhang</span>,&#32;
    <meta itemprop="givenName" content="Chong" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Agarwal</span>,&#32;
    <meta itemprop="givenName" content="Sandhini" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Slama</span>,&#32;
    <meta itemprop="givenName" content="Katarina" />
    K.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Ray</span>,&#32;
    <meta itemprop="givenName" content="Alex" />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Schulman</span>,&#32;
    <meta itemprop="givenName" content="John" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Hilton</span>,&#32;
    <meta itemprop="givenName" content="Jacob" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Kelton</span>,&#32;
    <meta itemprop="givenName" content="Fraser" />
    F.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Miller</span>,&#32;
    <meta itemprop="givenName" content="Luke" />
    L.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Simens</span>,&#32;
    <meta itemprop="givenName" content="Maddie" />
    M.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Askell</span>,&#32;
    <meta itemprop="givenName" content="Amanda" />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Welinder</span>,&#32;
    <meta itemprop="givenName" content="Peter" />
    P.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Christiano</span>,&#32;
    <meta itemprop="givenName" content="Paul" />
    P.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Leike</span>,&#32;
    <meta itemprop="givenName" content="Jan" />
    J.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lowe</span>,&#32;
    <meta itemprop="givenName" content="Ryan" />
    R.</span>
  &#32;
    (<span itemprop="datePublished">2022</span>).
  &#32;<span itemprop="name">Training language models to follow instructions with human feedback</span>.&#32;Retrieved from&#32;
  <a href="http://arxiv.org/abs/2203.02155"
     itemprop="identifier"
     itemtype="https://schema.org/URL">http://arxiv.org/abs/2203.02155</a></span>




</span></span>)</span>.</p>
    </figcaption>
</figure></center>
<h2 id="version-history">Version history<a hidden class="anchor" aria-hidden="true" href="#version-history">#</a></h2>
<ul>
<li><strong>v0.3</strong> (2023-11-23): minor corrections and tweaks.</li>
<li><strong>v0.2</strong> (2023-03-14): major rewrite, including adding section on novel evaluation methods.</li>
<li><strong>v0.1</strong> (2023-03-06): first public draft.</li>
</ul>


    



















<h2>Citation</h2>

<p>If you found this post useful for your work, please consider citing it as:

    <blockquote>
<p>Findeis, Arduin. (Mar 2023). A short exploration of language model evaluation approaches. Retrieved from <a href="https://arduin.io/blog/eval-exploration/">https://arduin.io/blog/eval-exploration/</a>.</p>
</blockquote>

    or

    <pre tabindex="0"><code> @article{Findeis2023Ashortexplorationoflanguagemodelevaluationapproaches,
        title = &#34;A short exploration of language model evaluation approaches&#34;,
        author = &#34;Findeis, Arduin&#34;,
        journal = &#34;arduin.io&#34;,
        year = &#34;2023&#34;,
        month = &#34;March&#34;,
        url = &#34;https://arduin.io/blog/eval-exploration/&#34;
 } 
</code></pre>

</p>

    
  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>
        
        <a href="https://arduin.io/"><img src="/favicon-32x32.png" alt="logo" style="width: 20px; margin: 0 auto;opacity:0.6;"></a>
    </span>
    <span>&copy; 2024 <a href="https://arduin.io/">arduin.io</a></span>
    <span>
        - powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a> with <a href='https://arduin.io/papermod-tweaks/' rel="noopener" target="_blank">tweaks</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script src="/js/table_beautify.js"></script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
