<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Some predictions for AI in 2025 | arduin.io</title>
<meta name="keywords" content="">
<meta name="description" content="As we enter the new year, I wanted to share some of my (tentative) predictions about AI development in 2025.">
<meta name="author" content="Arduin Findeis">
<link rel="canonical" href="https://arduin.io/blog/ai-predictions-2025/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.97173b9cc135611d0f7b99e6d2436218d03f30d019c115fd8b3f323360d9bb7e.css" integrity="sha256-lxc7nME1YR0Pe5nm0kNiGNA/MNAZwRX9iz8yM2DZu34=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://arduin.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://arduin.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://arduin.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://arduin.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://arduin.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://arduin.io/blog/ai-predictions-2025/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><script data-goatcounter="https://gbqtk.goatcounter.com/count"
        async src="//gc.zgo.at/count.js"></script><meta property="og:title" content="Some predictions for AI in 2025" />
<meta property="og:description" content="As we enter the new year, I wanted to share some of my (tentative) predictions about AI development in 2025." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://arduin.io/blog/ai-predictions-2025/" /><meta property="article:section" content="blog" />
<meta property="article:published_time" content="2025-01-09T10:00:00+00:00" />
<meta property="article:modified_time" content="2025-01-09T10:00:00+00:00" />

<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Some predictions for AI in 2025">
<meta name="twitter:description" content="As we enter the new year, I wanted to share some of my (tentative) predictions about AI development in 2025.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Blog",
      "item": "https://arduin.io/blog/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Some predictions for AI in 2025",
      "item": "https://arduin.io/blog/ai-predictions-2025/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Some predictions for AI in 2025",
  "name": "Some predictions for AI in 2025",
  "description": "As we enter the new year, I wanted to share some of my (tentative) predictions about AI development in 2025.",
  "keywords": [
    
  ],
  "articleBody": "As we enter the new year, I wanted to share some of my (tentative) predictions about AI development in 2025. Below, I predict three changes that I believe will have profound impact on AI research and development. This post is inherently an incomplete list, many other predictions could be added but are omitted (e.g. around agent use-cases). For simplicity, I refer to the largest multi-modal generative AI models as “AI” here — my predictions don’t necessarily apply to other AI models. Disclaimer: These predictions were made at the beginning of 2025 and may very well turn out to be wrong.\nPrediction 1: Voice-based AI will become more popular Interacting with AI models via text-based chat interfaces can be tedious. Voice-based interfaces promise a more natural interaction. Yet, traditional voice-based interfaces (such as Google Assistant, Alexa, or Siri) lack the latency and reasoning capabilities to serve as a satisfying voice-based alternative to ChatGPT. Traditionally, such interfaces rely on multiple separate components to solve speech recognition, reasoning and text-to-speech tasks. In 2024, we saw significant progress towards (probably) fully end-to-end models like OpenAI’s GPT-4o via Advanced Voice Mode or the Realtime API. Yet, these methods are still prohibitively expensive for many use-cases and interactions still leave something to be desired, e.g. they could feel more natural. I believe that in 2025 we will see further progress in this front as other developers release their Advanced Voice Mode competitors. This development will transfer users from text-based to voice-based AI interfaces and enable AI use in scenarios where text-only interfaces prevented use. Use-cases for which a call with a person is perceived as more helpful or easier than text chat will likely be most affected. Whilst claiming an increase of voice-based AI interactions is not controversial, I believe people generally under-appreciate the extent of the incoming shift towards voice. In my opinion, voice may eventually become the dominant (but not only) interface with AI models.\nPrediction 2: AI will become more personalized There is no single person that everyone likes to talk to. People differ in who they enjoy talking with. Similarly, it is unlikely that we want to keep to talking to effectively the same vanilla AI models. Many interfaces already provide some form of personalization (e.g. ChatGPT’s memory), though the overall level of personalization remains limited. I expect the level of personalization to increase beyond what is currently offered. In particular, I expect that, as for many chat-based tasks models solve tasks functionally reliably well, the focus in 2025 will be more on the style and personality of models. A key bottleneck will be trust: full personalisation requires access to extensive private data. Each model provider’s credibility in protecting such data will be critical for such use-cases. Personally, there is a lot of useful data that I am unwilling to send to most providers (e.g. health data). On-device models may be able to address these privacy concerns for some use-cases.\nPrediction 3: Performance will scale better with inference cost Prior to the o3 model generation, it was difficult to improve an AI model’s response quality for a given task beyond a certain point by generating more tokens. For many tasks, prompting GPT-4o with some form of chain-of-thought was the best you could do. The marginal utility of spending another dollar on token inference diminished quickly beyond this point. For many tasks, this meant that someone willing to spend 1 million USD on generating a response could not get more utility than someone spending 100 USD. AI responses were a form of satiated good, similar to the iPhone. With the new generation of models that perform some form of search and are fine-tuned for long multi-step reasoning (e.g. OpenAI’s o3 model), the marginal utility of additional spending potentially becomes non-zero even at large scales - spending more money on exploring the solution-space pays off better. I predict that in 2025 AI will increasingly become less of a satiated good: for a given task, the marginal utility of additional AI inference will diminish less quickly. Performance will scale better with inference cost. This change will have a profound impact on the economics of serving AI models.\nConclusion I look forward to finding out whether and how correct these predictions will have been. Reach out if you have any feedback or thoughts to share!\nAcknowledgement Big thanks to Timo Kaufmann, Benjamin Minixhofer, Victor Bourgin for their helpful feedback on earlier versions of this post. All errors are my own of course.\n",
  "wordCount" : "746",
  "inLanguage": "en",
  "datePublished": "2025-01-09T10:00:00Z",
  "dateModified": "2025-01-09T10:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Arduin Findeis"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://arduin.io/blog/ai-predictions-2025/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "arduin.io",
    "logo": {
      "@type": "ImageObject",
      "url": "https://arduin.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://arduin.io/" accesskey="h" title="arduin.io (Alt + H)">arduin.io</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://arduin.io/" title="Home">
                    <span>Home</span>
                </a>
            </li>
            <li>
                <a href="https://arduin.io/research" title="Research">
                    <span>Research</span>
                </a>
            </li>
            <li>
                <a href="https://arduin.io/projects" title="Projects">
                    <span>Projects</span>
                </a>
            </li>
            <li>
                <a href="https://arduin.io/bio" title="Bio">
                    <span>Bio</span>
                </a>
            </li>
            <li>
                <a href="https://arduin.io/blog" title="Blog">
                    <span>Blog</span>
                </a>
            </li>
            <li>
                <a href="https://arduin.io/newsletter" title="Newsletter">
                    <span>Newsletter</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <link rel="stylesheet" type="text/css" href="/hugo-cite.css" />
    
    <h1 class="post-title entry-hint-parent">
      Some predictions for AI in 2025
    </h1>
    
    <div class="post-meta"><span title='2025-01-09 10:00:00 +0000 UTC'>January 9, 2025</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;Arduin Findeis

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#prediction-1-voice-based-ai-will-become-more-popular" aria-label="Prediction 1: Voice-based AI will become more popular">Prediction 1: Voice-based AI will become more popular</a></li>
                <li>
                    <a href="#prediction-2-ai-will-become-more-personalized" aria-label="Prediction 2: AI will become more personalized">Prediction 2: AI will become more personalized</a></li>
                <li>
                    <a href="#prediction-3-performance-will-scale-better-with-inference-cost" aria-label="Prediction 3: Performance will scale better with inference cost">Prediction 3: Performance will scale better with inference cost</a></li>
                <li>
                    <a href="#conclusion" aria-label="Conclusion">Conclusion</a></li>
                <li>
                    <a href="#acknowledgement" aria-label="Acknowledgement">Acknowledgement</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p>As we enter the new year, I wanted to share some of my (tentative) predictions about AI development in 2025. Below, I predict three changes that I believe will have profound impact on AI research and development. This post is inherently an incomplete list, many other predictions could be added but are omitted (e.g. around agent use-cases). For simplicity, I refer to the largest multi-modal generative AI models as &ldquo;AI&rdquo; here &mdash; my predictions don&rsquo;t necessarily apply to other AI models. <em>Disclaimer: These predictions were made at the beginning of 2025 and may very well turn out to be wrong.</em></p>
<hr>
<center>
<img src="img/pred_audio_v2.png" width="200px" alt="Description of image">
</center>
<h2 id="prediction-1-voice-based-ai-will-become-more-popular">Prediction 1: Voice-based AI will become more popular<a hidden class="anchor" aria-hidden="true" href="#prediction-1-voice-based-ai-will-become-more-popular">#</a></h2>
<p>Interacting with AI models via <em>text-based</em> chat interfaces can be tedious. <em>Voice-based</em> interfaces promise a more natural interaction. Yet, traditional voice-based interfaces (such as <em>Google Assistant</em>, <em>Alexa</em>, or <em>Siri</em>) lack the latency and reasoning capabilities to serve as a satisfying voice-based alternative to ChatGPT. Traditionally, such interfaces rely on multiple separate components to solve speech recognition, reasoning and text-to-speech tasks. In 2024, we saw significant progress towards (probably) fully end-to-end models like OpenAI&rsquo;s GPT-4o via <a href="https://help.openai.com/en/articles/8400625-voice-mode-faq">Advanced Voice Mode</a> or the <a href="https://openai.com/index/introducing-the-realtime-api/">Realtime API</a>. Yet, these methods are still <a href="https://community.openai.com/t/realtime-api-extremely-expensive/966825">prohibitively expensive</a> for many use-cases and interactions still leave something to be desired, e.g. they could feel more natural. I believe that in 2025 we will see further progress in this front as other developers release their Advanced Voice Mode competitors. This development will transfer users from text-based to voice-based AI interfaces and enable AI use in scenarios where text-only interfaces prevented use. Use-cases for which a call with a person is perceived as more helpful or easier than text chat will likely be most affected. Whilst claiming an increase of voice-based AI interactions is not controversial, I believe people generally under-appreciate the extent of the incoming shift towards voice. In my opinion, voice may eventually become the dominant (but not only) interface with AI models.</p>
<hr>
<center>
<img src="img/pred_person_v2.png" width="280px" alt="Description of image">
</center>
<h2 id="prediction-2-ai-will-become-more-personalized">Prediction 2: AI will become more personalized<a hidden class="anchor" aria-hidden="true" href="#prediction-2-ai-will-become-more-personalized">#</a></h2>
<p>There is no single person that everyone likes to talk to. People differ in who they enjoy talking with. Similarly, it is unlikely that we want to keep to talking to effectively the same vanilla AI models. Many interfaces already provide some form of personalization (e.g. ChatGPT&rsquo;s <a href="https://openai.com/index/memory-and-new-controls-for-chatgpt/">memory</a>), though the overall level of personalization remains limited. I expect the level of personalization to increase beyond what is currently offered. In particular, I expect that, as for many chat-based tasks models solve tasks functionally reliably well, the focus in 2025 will be more on the style and personality of models. A key bottleneck will be <em>trust</em>: full personalisation requires access to extensive private data. Each model provider&rsquo;s credibility in protecting such data will be critical for such use-cases. Personally, there is a lot of useful data that I am unwilling to send to most providers (e.g. health data). On-device models may be able to address these privacy concerns for some use-cases.</p>
<hr>
<center>
<img src="img/pred_inference_v3.png" width="300px" alt="Description of image">
</center>
<h2 id="prediction-3-performance-will-scale-better-with-inference-cost">Prediction 3: Performance will scale better with inference cost<a hidden class="anchor" aria-hidden="true" href="#prediction-3-performance-will-scale-better-with-inference-cost">#</a></h2>
<p>Prior to the <a href="https://arcprize.org/blog/oai-o3-pub-breakthrough">o3 model</a> generation, it was difficult to improve an AI model&rsquo;s response quality for a given task beyond a certain point by generating more tokens. For many tasks, prompting GPT-4o with some form of <a href="https://arxiv.org/abs/2201.11903">chain-of-thought</a> was the best you could do. The marginal utility of spending another dollar on token inference diminished quickly beyond this point. For many tasks, this meant that someone willing to spend 1 million USD on generating a response could not get more utility than someone spending 100 USD. AI responses were a form of <a href="https://en.wikipedia.org/wiki/Economic_satiation">satiated good</a>, similar to the iPhone.
With the new generation of models that perform some form of search and are fine-tuned for long multi-step reasoning (e.g. OpenAI&rsquo;s o3 model), the marginal utility of additional spending potentially becomes non-zero even at large scales - spending more money on exploring the solution-space pays off better. I predict that in 2025 AI will increasingly become less of a satiated good: for a given task, the marginal utility of additional AI inference will diminish less quickly. Performance will scale better with inference cost. This change will have a profound impact on the economics of serving AI models.</p>
<hr>
<h2 id="conclusion">Conclusion<a hidden class="anchor" aria-hidden="true" href="#conclusion">#</a></h2>
<p>I look forward to finding out whether and how correct these predictions will have been. <a href="https://arduin.io/">Reach out</a> if you have any feedback or thoughts to share!</p>
<h2 id="acknowledgement">Acknowledgement<a hidden class="anchor" aria-hidden="true" href="#acknowledgement">#</a></h2>
<p>Big thanks to Timo Kaufmann, Benjamin Minixhofer, Victor Bourgin for their helpful feedback on earlier versions of this post. All errors are my own of course.</p>


    



















<h2>Citation</h2>

<p>If you found this post useful for your work, please consider citing it as:

    <blockquote>
<p>Findeis, Arduin. (Jan 2025). Some predictions for AI in 2025. Retrieved from <a href="https://arduin.io/blog/ai-predictions-2025/">https://arduin.io/blog/ai-predictions-2025/</a>.</p></blockquote>

    or

    <pre tabindex="0"><code> @article{Findeis2023SomepredictionsforAIin2025,
        title = &#34;Some predictions for AI in 2025&#34;,
        author = &#34;Findeis, Arduin&#34;,
        journal = &#34;arduin.io&#34;,
        year = &#34;2025&#34;,
        month = &#34;January&#34;,
        url = &#34;https://arduin.io/blog/ai-predictions-2025/&#34;
 } 
</code></pre>

</p>

    
  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>
        
        <a href="https://arduin.io/"><img src="/favicon-32x32.png" alt="logo" style="width: 20px; margin: 0 auto;opacity:0.6;"></a>
    </span>
    <span>&copy; 2025 <a href="https://arduin.io/">arduin.io</a></span>
    <span>
        - powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a> with <a href='https://arduin.io/papermod-tweaks/' rel="noopener" target="_blank">tweaks</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script src="/js/table_beautify.js"></script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
